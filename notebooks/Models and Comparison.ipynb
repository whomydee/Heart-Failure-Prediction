{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the training and testing instances from the dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "picklefile_tX = open('../dump/training_features.pickle', 'rb')\n",
    "training_features = pickle.load(picklefile_tX)\n",
    "picklefile_tY = open('../dump/training_labels.pickle', 'rb')\n",
    "training_labels = pickle.load(picklefile_tY)\n",
    "\n",
    "picklefile_TX = open('../dump/testing_features.pickle', 'rb')\n",
    "testing_features = pickle.load(picklefile_TX)\n",
    "picklefile_TY = open('../dump/testing_labels.pickle', 'rb')\n",
    "testing_labels = pickle.load(picklefile_TY)\n",
    "\n",
    "\n",
    "picklefile_tX.close()\n",
    "picklefile_tY.close()\n",
    "picklefile_TX.close()\n",
    "picklefile_TY.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using logsitic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shad Humydee\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "Accuracy: 73.17073170731707\n",
      "Precision:  78.35803477652003\n",
      "Recall:  73.17073170731707\n",
      "FScore:  73.62191459752435\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "LRegression = LogisticRegression().fit(training_features, training_labels)\n",
    "\n",
    "prediction_LRegression = LRegression.predict(testing_features)\n",
    "\n",
    "print(np.unique(prediction_LRegression))\n",
    "\n",
    "acc_log_reg = accuracy_score(prediction_LRegression, testing_labels) * 100\n",
    "\n",
    "print(\"Accuracy:\", acc_log_reg)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(testing_labels, prediction_LRegression, average='weighted')\n",
    "\n",
    "print(\"Precision: \", precision*100)\n",
    "print(\"Recall: \", recall*100)\n",
    "print(\"FScore: \", fscore*100)\n",
    "# print(\"Support: \", support*100)\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(testing_labels, prediction_LRegression)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shad Humydee\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "Accuracy: 97.5609756097561\n",
      "Precision:  97.71341463414635\n",
      "Recall:  97.5609756097561\n",
      "FScore:  97.57640270899861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "# pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "\n",
    "\n",
    "RF_classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "RF_classifier.fit(training_features, training_labels)\n",
    "y_pred = RF_classifier.predict(testing_features)\n",
    "\n",
    "print(np.unique(y_pred))\n",
    "\n",
    "acc_rf_classifier = (1 - metrics.mean_absolute_error(testing_labels, y_pred)) * 100\n",
    "\n",
    "print('Accuracy:', acc_rf_classifier)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(testing_labels, y_pred, average='weighted')\n",
    "\n",
    "print(\"Precision: \", precision*100)\n",
    "print(\"Recall: \", recall*100)\n",
    "print(\"FScore: \", fscore*100)\n",
    "# print(\"Support: \", support*100)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(testing_labels, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shad Humydee\\anaconda3\\envs\\py36\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Shad Humydee\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 100.00%\n",
      "Precision:  100.0\n",
      "Recall:  100.0\n",
      "FScore:  100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "# print(model)\n",
    "\n",
    "model.fit(training_features, training_labels)\n",
    "\n",
    "y_pred = model.predict(testing_features)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# print(predictions)\n",
    "# print(testing_labels)\n",
    "\n",
    "# evaluate predictions\n",
    "acc_XGB_classifier = accuracy_score(testing_labels, predictions) * 100\n",
    "print(\"Accuracy: %.2f%%\" % (acc_XGB_classifier))\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(testing_labels, y_pred, average='weighted')\n",
    "\n",
    "print(\"Precision: \", precision*100)\n",
    "print(\"Recall: \", recall*100)\n",
    "print(\"FScore: \", fscore*100)\n",
    "# print(\"Support: \", support*100)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(testing_labels, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 75ms/step - loss: 0.7180 - accuracy: 0.6265 - val_loss: 1.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6265 - val_loss: 1.0465 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.6296 - val_loss: 0.9578 - val_accuracy: 0.0610\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6531 - accuracy: 0.6420 - val_loss: 0.9406 - val_accuracy: 0.0610\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6505 - accuracy: 0.6420 - val_loss: 0.9506 - val_accuracy: 0.0610\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6470 - accuracy: 0.6451 - val_loss: 0.9721 - val_accuracy: 0.0854\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6420 - val_loss: 0.9464 - val_accuracy: 0.1098\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.6543 - val_loss: 0.9511 - val_accuracy: 0.1098\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.6574 - val_loss: 0.9669 - val_accuracy: 0.1098\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6376 - accuracy: 0.6574 - val_loss: 0.9922 - val_accuracy: 0.0610\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6368 - accuracy: 0.6574 - val_loss: 0.9774 - val_accuracy: 0.0976\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6543 - val_loss: 0.9517 - val_accuracy: 0.1098\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6605 - val_loss: 0.9359 - val_accuracy: 0.1098\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6543 - val_loss: 0.9577 - val_accuracy: 0.1098\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6282 - accuracy: 0.6605 - val_loss: 0.9831 - val_accuracy: 0.1098\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6265 - accuracy: 0.6605 - val_loss: 1.0094 - val_accuracy: 0.1098\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.6605 - val_loss: 1.0177 - val_accuracy: 0.1098\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6605 - val_loss: 0.9471 - val_accuracy: 0.1585\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6667 - val_loss: 0.9708 - val_accuracy: 0.1585\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.6667 - val_loss: 0.9713 - val_accuracy: 0.1585\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6192 - accuracy: 0.6667 - val_loss: 0.9697 - val_accuracy: 0.1585\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6177 - accuracy: 0.6667 - val_loss: 0.9564 - val_accuracy: 0.1585\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.6667 - val_loss: 0.9720 - val_accuracy: 0.1585\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.6728 - val_loss: 0.9728 - val_accuracy: 0.1341\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.6636 - val_loss: 0.9125 - val_accuracy: 0.1829\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6148 - accuracy: 0.6698 - val_loss: 0.9439 - val_accuracy: 0.1829\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6122 - accuracy: 0.6698 - val_loss: 0.9617 - val_accuracy: 0.1829\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6110 - accuracy: 0.6698 - val_loss: 0.9961 - val_accuracy: 0.1341\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.6759 - val_loss: 0.9893 - val_accuracy: 0.1585\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.6759 - val_loss: 1.0156 - val_accuracy: 0.1585\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6728 - val_loss: 0.9672 - val_accuracy: 0.1829\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.6728 - val_loss: 0.9865 - val_accuracy: 0.1829\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6057 - accuracy: 0.6790 - val_loss: 0.9906 - val_accuracy: 0.1829\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6039 - accuracy: 0.6728 - val_loss: 0.9356 - val_accuracy: 0.1829\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6027 - accuracy: 0.6759 - val_loss: 0.9277 - val_accuracy: 0.1829\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6759 - val_loss: 0.9262 - val_accuracy: 0.1829\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6790 - val_loss: 0.8866 - val_accuracy: 0.1951\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6944 - val_loss: 0.8740 - val_accuracy: 0.1951\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5980 - accuracy: 0.6975 - val_loss: 0.9599 - val_accuracy: 0.1829\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6852 - val_loss: 0.9536 - val_accuracy: 0.1829\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5923 - accuracy: 0.6883 - val_loss: 0.8977 - val_accuracy: 0.2073\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5917 - accuracy: 0.7006 - val_loss: 0.9626 - val_accuracy: 0.1829\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.6944 - val_loss: 0.9315 - val_accuracy: 0.1951\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7037 - val_loss: 0.9223 - val_accuracy: 0.2073\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5847 - accuracy: 0.7006 - val_loss: 0.9978 - val_accuracy: 0.1829\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5846 - accuracy: 0.6944 - val_loss: 0.9898 - val_accuracy: 0.1829\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.6975 - val_loss: 0.9608 - val_accuracy: 0.1951\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.7068 - val_loss: 0.9863 - val_accuracy: 0.1951\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5781 - accuracy: 0.7160 - val_loss: 0.9407 - val_accuracy: 0.2073\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5762 - accuracy: 0.7099 - val_loss: 0.9484 - val_accuracy: 0.2073\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.7068 - val_loss: 0.8642 - val_accuracy: 0.2561\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5722 - accuracy: 0.7099 - val_loss: 0.9272 - val_accuracy: 0.2073\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.7253 - val_loss: 0.8765 - val_accuracy: 0.2927\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.7160 - val_loss: 0.9073 - val_accuracy: 0.2927\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5653 - accuracy: 0.7222 - val_loss: 0.8749 - val_accuracy: 0.3171\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.7222 - val_loss: 0.8726 - val_accuracy: 0.3780\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7346 - val_loss: 0.8410 - val_accuracy: 0.4146\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.7377 - val_loss: 0.8698 - val_accuracy: 0.4146\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5519 - accuracy: 0.7377 - val_loss: 0.8759 - val_accuracy: 0.4146\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5493 - accuracy: 0.7346 - val_loss: 0.9142 - val_accuracy: 0.4024\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5455 - accuracy: 0.7377 - val_loss: 0.8056 - val_accuracy: 0.4634\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.8141 - val_accuracy: 0.4390\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7346 - val_loss: 0.9815 - val_accuracy: 0.3171\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5360 - accuracy: 0.7284 - val_loss: 0.8812 - val_accuracy: 0.4146\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.7377 - val_loss: 0.8586 - val_accuracy: 0.4390\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.7315 - val_loss: 0.7783 - val_accuracy: 0.5000\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7407 - val_loss: 0.7953 - val_accuracy: 0.4756\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7284 - val_loss: 0.7509 - val_accuracy: 0.4756\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7315 - val_loss: 0.9522 - val_accuracy: 0.3537\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.7377 - val_loss: 0.7331 - val_accuracy: 0.5122\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5231 - accuracy: 0.7562 - val_loss: 0.8128 - val_accuracy: 0.4512\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5155 - accuracy: 0.7438 - val_loss: 0.9081 - val_accuracy: 0.3902\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7438 - val_loss: 0.8034 - val_accuracy: 0.4146\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7438 - val_loss: 0.9435 - val_accuracy: 0.3780\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7315 - val_loss: 0.7384 - val_accuracy: 0.5244\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.7623 - val_loss: 1.0027 - val_accuracy: 0.3537\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7593 - val_loss: 0.9882 - val_accuracy: 0.3780\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5077 - accuracy: 0.7685 - val_loss: 0.7995 - val_accuracy: 0.4634\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5025 - accuracy: 0.7685 - val_loss: 0.9247 - val_accuracy: 0.3902\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.7654 - val_loss: 0.8581 - val_accuracy: 0.4146\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7593 - val_loss: 0.7428 - val_accuracy: 0.5366\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7747 - val_loss: 0.9039 - val_accuracy: 0.3902\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.7654 - val_loss: 0.8557 - val_accuracy: 0.4756\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4906 - accuracy: 0.7654 - val_loss: 0.8297 - val_accuracy: 0.4634\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.7623 - val_loss: 0.6336 - val_accuracy: 0.6585\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.7809 - val_loss: 0.8201 - val_accuracy: 0.4878\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7654 - val_loss: 0.7213 - val_accuracy: 0.5244\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7685 - val_loss: 0.8145 - val_accuracy: 0.4512\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7747 - val_loss: 0.5818 - val_accuracy: 0.7195\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7809 - val_loss: 0.5113 - val_accuracy: 0.8171\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7685 - val_loss: 0.7994 - val_accuracy: 0.4146\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7685 - val_loss: 0.6864 - val_accuracy: 0.5244\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.8025 - val_loss: 1.1123 - val_accuracy: 0.3293\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7840 - val_loss: 0.8719 - val_accuracy: 0.4146\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7654 - val_loss: 0.7175 - val_accuracy: 0.5000\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7870 - val_loss: 0.5430 - val_accuracy: 0.7805\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7747 - val_loss: 0.5670 - val_accuracy: 0.7317\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.9686 - val_accuracy: 0.3902\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.9902 - val_accuracy: 0.3780\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7840 - val_loss: 0.8035 - val_accuracy: 0.4390\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7870 - val_loss: 0.7240 - val_accuracy: 0.5366\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7809 - val_loss: 0.9937 - val_accuracy: 0.3659\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.7716 - val_loss: 0.5010 - val_accuracy: 0.8171\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7809 - val_loss: 0.6899 - val_accuracy: 0.5488\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7963 - val_loss: 0.6441 - val_accuracy: 0.7195\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7994 - val_loss: 0.6505 - val_accuracy: 0.6951\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7747 - val_loss: 0.6147 - val_accuracy: 0.7683\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7932 - val_loss: 0.9866 - val_accuracy: 0.4024\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7932 - val_loss: 0.6705 - val_accuracy: 0.6341\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.8219 - val_accuracy: 0.4146\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7963 - val_loss: 0.6907 - val_accuracy: 0.5732\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.8025 - val_loss: 0.8051 - val_accuracy: 0.4390\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.8086 - val_loss: 0.5101 - val_accuracy: 0.8171\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.8025 - val_loss: 0.7021 - val_accuracy: 0.5976\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.7994 - val_loss: 0.7193 - val_accuracy: 0.5610\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.8148 - val_loss: 0.7584 - val_accuracy: 0.4878\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8086 - val_loss: 0.6050 - val_accuracy: 0.7561\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7870 - val_loss: 0.4771 - val_accuracy: 0.8537\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.8210 - val_loss: 0.7278 - val_accuracy: 0.5244\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8086 - val_loss: 0.8806 - val_accuracy: 0.4268\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7963 - val_loss: 0.6575 - val_accuracy: 0.6829\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.3985 - val_accuracy: 0.8902\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8056 - val_loss: 0.8580 - val_accuracy: 0.4268\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.8025 - val_loss: 0.7355 - val_accuracy: 0.5488\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.8086 - val_loss: 0.6504 - val_accuracy: 0.6707\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8210 - val_loss: 0.6868 - val_accuracy: 0.6098\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.8148 - val_loss: 0.4755 - val_accuracy: 0.8293\n",
      "Epoch 128/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8302 - val_loss: 0.8909 - val_accuracy: 0.4512\n",
      "Epoch 129/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8179 - val_loss: 0.3703 - val_accuracy: 0.9146\n",
      "Epoch 130/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.8179 - val_loss: 0.3590 - val_accuracy: 0.9146\n",
      "Epoch 131/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.8025 - val_loss: 0.8641 - val_accuracy: 0.4390\n",
      "Epoch 132/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7994 - val_loss: 1.1429 - val_accuracy: 0.3415\n",
      "Epoch 133/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8148 - val_loss: 0.9731 - val_accuracy: 0.3780\n",
      "Epoch 134/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7994 - val_loss: 0.7253 - val_accuracy: 0.5610\n",
      "Epoch 135/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8025 - val_loss: 0.4345 - val_accuracy: 0.8537\n",
      "Epoch 136/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8364 - val_loss: 0.3278 - val_accuracy: 0.9146\n",
      "Epoch 137/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7932 - val_loss: 0.7478 - val_accuracy: 0.5732\n",
      "Epoch 138/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8241 - val_loss: 0.6006 - val_accuracy: 0.7927\n",
      "Epoch 139/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8179 - val_loss: 0.8711 - val_accuracy: 0.4390\n",
      "Epoch 140/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8025 - val_loss: 0.6014 - val_accuracy: 0.7317\n",
      "Epoch 141/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8272 - val_loss: 0.4597 - val_accuracy: 0.8537\n",
      "Epoch 142/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7994 - val_loss: 0.3823 - val_accuracy: 0.8902\n",
      "Epoch 143/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.8333 - val_loss: 0.4518 - val_accuracy: 0.8659\n",
      "Epoch 144/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8364 - val_loss: 0.4757 - val_accuracy: 0.8659\n",
      "Epoch 145/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8241 - val_loss: 0.6729 - val_accuracy: 0.5976\n",
      "Epoch 146/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8333 - val_loss: 0.7260 - val_accuracy: 0.6463\n",
      "Epoch 147/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8241 - val_loss: 0.7357 - val_accuracy: 0.5610\n",
      "Epoch 148/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8210 - val_loss: 1.6230 - val_accuracy: 0.2805\n",
      "Epoch 149/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7870 - val_loss: 0.7130 - val_accuracy: 0.5732\n",
      "Epoch 150/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8364 - val_loss: 0.5667 - val_accuracy: 0.7561\n",
      "Epoch 151/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8488 - val_loss: 0.5929 - val_accuracy: 0.7317\n",
      "Epoch 152/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8488 - val_loss: 0.7922 - val_accuracy: 0.6341\n",
      "Epoch 153/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8241 - val_loss: 0.7478 - val_accuracy: 0.5732\n",
      "Epoch 154/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8302 - val_loss: 0.6403 - val_accuracy: 0.7195\n",
      "Epoch 155/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8395 - val_loss: 0.3420 - val_accuracy: 0.9146\n",
      "Epoch 156/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8117 - val_loss: 0.5720 - val_accuracy: 0.7805\n",
      "Epoch 157/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8210 - val_loss: 0.5279 - val_accuracy: 0.8171\n",
      "Epoch 158/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8519 - val_loss: 0.8534 - val_accuracy: 0.4634\n",
      "Epoch 159/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8364 - val_loss: 0.9855 - val_accuracy: 0.4268\n",
      "Epoch 160/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8241 - val_loss: 0.8660 - val_accuracy: 0.4634\n",
      "Epoch 161/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8179 - val_loss: 0.6151 - val_accuracy: 0.7561\n",
      "Epoch 162/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8549 - val_loss: 1.0523 - val_accuracy: 0.3780\n",
      "Epoch 163/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8210 - val_loss: 0.3951 - val_accuracy: 0.8780\n",
      "Epoch 164/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8549 - val_loss: 0.6111 - val_accuracy: 0.7317\n",
      "Epoch 165/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8426 - val_loss: 0.7893 - val_accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8302 - val_loss: 0.4501 - val_accuracy: 0.8537\n",
      "Epoch 167/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.7994 - val_loss: 1.0017 - val_accuracy: 0.4390\n",
      "Epoch 168/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8241 - val_loss: 0.3146 - val_accuracy: 0.9146\n",
      "Epoch 169/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8302 - val_loss: 0.8015 - val_accuracy: 0.5610\n",
      "Epoch 170/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8426 - val_loss: 0.7126 - val_accuracy: 0.6098\n",
      "Epoch 171/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8457 - val_loss: 1.3102 - val_accuracy: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8302 - val_loss: 0.6007 - val_accuracy: 0.7805\n",
      "Epoch 173/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8549 - val_loss: 0.4644 - val_accuracy: 0.8293\n",
      "Epoch 174/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8302 - val_loss: 0.8190 - val_accuracy: 0.5122\n",
      "Epoch 175/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8395 - val_loss: 0.7667 - val_accuracy: 0.5610\n",
      "Epoch 176/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3776 - accuracy: 0.8395 - val_loss: 0.3696 - val_accuracy: 0.8902\n",
      "Epoch 177/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8272 - val_loss: 0.4399 - val_accuracy: 0.8537\n",
      "Epoch 178/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8395 - val_loss: 0.6421 - val_accuracy: 0.7073\n",
      "Epoch 179/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8580 - val_loss: 1.7866 - val_accuracy: 0.2683\n",
      "Epoch 180/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8241 - val_loss: 0.5604 - val_accuracy: 0.7927\n",
      "Epoch 181/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8302 - val_loss: 0.5400 - val_accuracy: 0.7927\n",
      "Epoch 182/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8549 - val_loss: 0.4428 - val_accuracy: 0.8293\n",
      "Epoch 183/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3693 - accuracy: 0.8549 - val_loss: 1.0700 - val_accuracy: 0.3902\n",
      "Epoch 184/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8426 - val_loss: 0.8281 - val_accuracy: 0.5366\n",
      "Epoch 185/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3669 - accuracy: 0.8395 - val_loss: 0.6137 - val_accuracy: 0.7683\n",
      "Epoch 186/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8611 - val_loss: 0.4558 - val_accuracy: 0.8537\n",
      "Epoch 187/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8549 - val_loss: 0.7338 - val_accuracy: 0.6220\n",
      "Epoch 188/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8549 - val_loss: 0.5923 - val_accuracy: 0.7561\n",
      "Epoch 189/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3676 - accuracy: 0.8580 - val_loss: 0.5838 - val_accuracy: 0.7805\n",
      "Epoch 190/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3556 - accuracy: 0.8704 - val_loss: 0.8485 - val_accuracy: 0.5610\n",
      "Epoch 191/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3554 - accuracy: 0.8580 - val_loss: 0.2938 - val_accuracy: 0.9146\n",
      "Epoch 192/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8148 - val_loss: 0.5808 - val_accuracy: 0.7927\n",
      "Epoch 193/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8580 - val_loss: 0.9674 - val_accuracy: 0.4390\n",
      "Epoch 194/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8333 - val_loss: 1.5591 - val_accuracy: 0.3171\n",
      "Epoch 195/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8333 - val_loss: 0.4264 - val_accuracy: 0.8780\n",
      "Epoch 196/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8642 - val_loss: 0.6680 - val_accuracy: 0.6829\n",
      "Epoch 197/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3482 - accuracy: 0.8642 - val_loss: 0.7797 - val_accuracy: 0.5610\n",
      "Epoch 198/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8611 - val_loss: 0.4055 - val_accuracy: 0.8902\n",
      "Epoch 199/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3543 - accuracy: 0.8611 - val_loss: 0.4229 - val_accuracy: 0.8537\n",
      "Epoch 200/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.8673 - val_loss: 0.6118 - val_accuracy: 0.7195\n",
      "Epoch 201/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8611 - val_loss: 0.5789 - val_accuracy: 0.7927\n",
      "Epoch 202/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8580 - val_loss: 0.4349 - val_accuracy: 0.8537\n",
      "Epoch 203/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8796 - val_loss: 0.4944 - val_accuracy: 0.7927\n",
      "Epoch 204/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.8673 - val_loss: 0.4564 - val_accuracy: 0.8293\n",
      "Epoch 205/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.8704 - val_loss: 0.6543 - val_accuracy: 0.7195\n",
      "Epoch 206/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.8549 - val_loss: 0.6112 - val_accuracy: 0.7439\n",
      "Epoch 207/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.8673 - val_loss: 0.5133 - val_accuracy: 0.7927\n",
      "Epoch 208/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.8796 - val_loss: 0.8692 - val_accuracy: 0.4878\n",
      "Epoch 209/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8673 - val_loss: 0.9263 - val_accuracy: 0.4634\n",
      "Epoch 210/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.8549 - val_loss: 1.0728 - val_accuracy: 0.3902\n",
      "Epoch 211/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8796 - val_loss: 0.4375 - val_accuracy: 0.8537\n",
      "Epoch 212/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8673 - val_loss: 0.5302 - val_accuracy: 0.7927\n",
      "Epoch 213/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3294 - accuracy: 0.8858 - val_loss: 0.5788 - val_accuracy: 0.7927\n",
      "Epoch 214/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3262 - accuracy: 0.8796 - val_loss: 0.4757 - val_accuracy: 0.7927\n",
      "Epoch 215/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8827 - val_loss: 0.3491 - val_accuracy: 0.9146\n",
      "Epoch 216/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.8611 - val_loss: 0.5263 - val_accuracy: 0.7561\n",
      "Epoch 217/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8796 - val_loss: 0.5238 - val_accuracy: 0.7561\n",
      "Epoch 218/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8673 - val_loss: 0.4613 - val_accuracy: 0.8171\n",
      "Epoch 219/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8673 - val_loss: 0.8262 - val_accuracy: 0.5610\n",
      "Epoch 220/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.8889 - val_loss: 0.4969 - val_accuracy: 0.7927\n",
      "Epoch 221/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3184 - accuracy: 0.8981 - val_loss: 0.7740 - val_accuracy: 0.6220\n",
      "Epoch 222/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3257 - accuracy: 0.8796 - val_loss: 0.3232 - val_accuracy: 0.8780\n",
      "Epoch 223/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8735 - val_loss: 0.3793 - val_accuracy: 0.9146\n",
      "Epoch 224/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8673 - val_loss: 0.3755 - val_accuracy: 0.8537\n",
      "Epoch 225/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.8642 - val_loss: 0.9352 - val_accuracy: 0.5732\n",
      "Epoch 226/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8642 - val_loss: 0.7593 - val_accuracy: 0.6829\n",
      "Epoch 227/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8642 - val_loss: 1.1488 - val_accuracy: 0.4024\n",
      "Epoch 228/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8735 - val_loss: 0.4602 - val_accuracy: 0.8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.8951 - val_loss: 0.5475 - val_accuracy: 0.7805\n",
      "Epoch 230/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8827 - val_loss: 0.4385 - val_accuracy: 0.8171\n",
      "Epoch 231/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8611 - val_loss: 0.8440 - val_accuracy: 0.5976\n",
      "Epoch 232/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.8765 - val_loss: 0.2866 - val_accuracy: 0.9146\n",
      "Epoch 233/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8827 - val_loss: 0.3467 - val_accuracy: 0.9146\n",
      "Epoch 234/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8642 - val_loss: 0.6107 - val_accuracy: 0.7073\n",
      "Epoch 235/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.8889 - val_loss: 0.9108 - val_accuracy: 0.4878\n",
      "Epoch 236/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3217 - accuracy: 0.8889 - val_loss: 1.3211 - val_accuracy: 0.3537\n",
      "Epoch 237/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8457 - val_loss: 0.7457 - val_accuracy: 0.6829\n",
      "Epoch 238/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.8858 - val_loss: 1.0954 - val_accuracy: 0.4756\n",
      "Epoch 239/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3217 - accuracy: 0.8796 - val_loss: 0.2696 - val_accuracy: 0.9146\n",
      "Epoch 240/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3368 - accuracy: 0.8642 - val_loss: 0.6912 - val_accuracy: 0.6951\n",
      "Epoch 241/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.8951 - val_loss: 1.1915 - val_accuracy: 0.3780\n",
      "Epoch 242/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3402 - accuracy: 0.8704 - val_loss: 0.5439 - val_accuracy: 0.7927\n",
      "Epoch 243/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3064 - accuracy: 0.9043 - val_loss: 0.5531 - val_accuracy: 0.7805\n",
      "Epoch 244/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3197 - accuracy: 0.8735 - val_loss: 0.7172 - val_accuracy: 0.7195\n",
      "Epoch 245/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8704 - val_loss: 0.2756 - val_accuracy: 0.9146\n",
      "Epoch 246/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.8395 - val_loss: 1.3623 - val_accuracy: 0.4024\n",
      "Epoch 247/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8673 - val_loss: 0.3332 - val_accuracy: 0.8780\n",
      "Epoch 248/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3095 - accuracy: 0.8827 - val_loss: 0.6326 - val_accuracy: 0.7683\n",
      "Epoch 249/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.8951 - val_loss: 0.5414 - val_accuracy: 0.7927\n",
      "Epoch 250/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.8889 - val_loss: 0.3837 - val_accuracy: 0.8780\n",
      "Epoch 251/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.8858 - val_loss: 1.1359 - val_accuracy: 0.4878\n",
      "Epoch 252/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.8580 - val_loss: 0.4676 - val_accuracy: 0.8171\n",
      "Epoch 253/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2874 - accuracy: 0.8981 - val_loss: 0.3419 - val_accuracy: 0.9146\n",
      "Epoch 254/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3208 - accuracy: 0.8611 - val_loss: 0.7165 - val_accuracy: 0.6951\n",
      "Epoch 255/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3058 - accuracy: 0.8796 - val_loss: 0.5008 - val_accuracy: 0.7927\n",
      "Epoch 256/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2968 - accuracy: 0.8796 - val_loss: 0.5549 - val_accuracy: 0.7927\n",
      "Epoch 257/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2969 - accuracy: 0.8981 - val_loss: 0.9545 - val_accuracy: 0.5366\n",
      "Epoch 258/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3032 - accuracy: 0.8858 - val_loss: 0.3478 - val_accuracy: 0.8780\n",
      "Epoch 259/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3044 - accuracy: 0.8858 - val_loss: 0.5359 - val_accuracy: 0.7805\n",
      "Epoch 260/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8704 - val_loss: 0.7692 - val_accuracy: 0.6707\n",
      "Epoch 261/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8951 - val_loss: 0.4729 - val_accuracy: 0.8171\n",
      "Epoch 262/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.8827 - val_loss: 0.8291 - val_accuracy: 0.6098\n",
      "Epoch 263/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8889 - val_loss: 1.7794 - val_accuracy: 0.3171\n",
      "Epoch 264/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8611 - val_loss: 0.6550 - val_accuracy: 0.7439\n",
      "Epoch 265/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2888 - accuracy: 0.8765 - val_loss: 0.5079 - val_accuracy: 0.7927\n",
      "Epoch 266/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3020 - accuracy: 0.8796 - val_loss: 0.4021 - val_accuracy: 0.8780\n",
      "Epoch 267/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2815 - accuracy: 0.8981 - val_loss: 0.4968 - val_accuracy: 0.8415\n",
      "Epoch 268/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3108 - accuracy: 0.8827 - val_loss: 0.4744 - val_accuracy: 0.8415\n",
      "Epoch 269/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 0.8858 - val_loss: 0.3134 - val_accuracy: 0.8780\n",
      "Epoch 270/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3075 - accuracy: 0.8889 - val_loss: 1.4458 - val_accuracy: 0.3537\n",
      "Epoch 271/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3193 - accuracy: 0.8580 - val_loss: 0.8503 - val_accuracy: 0.6341\n",
      "Epoch 272/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.8765 - val_loss: 0.5840 - val_accuracy: 0.7683\n",
      "Epoch 273/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2820 - accuracy: 0.9105 - val_loss: 0.5952 - val_accuracy: 0.7683\n",
      "Epoch 274/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.8827 - val_loss: 0.4144 - val_accuracy: 0.8415\n",
      "Epoch 275/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2779 - accuracy: 0.8920 - val_loss: 0.6287 - val_accuracy: 0.7561\n",
      "Epoch 276/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2918 - accuracy: 0.8889 - val_loss: 0.5477 - val_accuracy: 0.8171\n",
      "Epoch 277/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2758 - accuracy: 0.9012 - val_loss: 0.3573 - val_accuracy: 0.8780\n",
      "Epoch 278/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.8858 - val_loss: 1.0781 - val_accuracy: 0.4146\n",
      "Epoch 279/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2769 - accuracy: 0.9105 - val_loss: 0.8849 - val_accuracy: 0.6220\n",
      "Epoch 280/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2920 - accuracy: 0.8981 - val_loss: 0.6748 - val_accuracy: 0.7195\n",
      "Epoch 281/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2704 - accuracy: 0.9043 - val_loss: 0.6028 - val_accuracy: 0.7561\n",
      "Epoch 282/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2892 - accuracy: 0.8827 - val_loss: 0.3451 - val_accuracy: 0.8780\n",
      "Epoch 283/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2875 - accuracy: 0.8796 - val_loss: 0.7779 - val_accuracy: 0.6829\n",
      "Epoch 284/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.9012 - val_loss: 1.0511 - val_accuracy: 0.5122\n",
      "Epoch 285/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3000 - accuracy: 0.8858 - val_loss: 0.4647 - val_accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2915 - accuracy: 0.8827 - val_loss: 0.2615 - val_accuracy: 0.9146\n",
      "Epoch 287/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.8735 - val_loss: 0.2974 - val_accuracy: 0.9146\n",
      "Epoch 288/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8827 - val_loss: 0.5223 - val_accuracy: 0.8415\n",
      "Epoch 289/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2693 - accuracy: 0.9012 - val_loss: 0.4477 - val_accuracy: 0.8415\n",
      "Epoch 290/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2618 - accuracy: 0.9074 - val_loss: 0.5818 - val_accuracy: 0.7927\n",
      "Epoch 291/1000\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.81 - 0s 7ms/step - loss: 0.2968 - accuracy: 0.8827 - val_loss: 0.5200 - val_accuracy: 0.8415\n",
      "Epoch 292/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2758 - accuracy: 0.8951 - val_loss: 0.4853 - val_accuracy: 0.8415\n",
      "Epoch 293/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2586 - accuracy: 0.9043 - val_loss: 0.2681 - val_accuracy: 0.9268\n",
      "Epoch 294/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2988 - accuracy: 0.8765 - val_loss: 0.4680 - val_accuracy: 0.8171\n",
      "Epoch 295/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2721 - accuracy: 0.9012 - val_loss: 1.2094 - val_accuracy: 0.5122\n",
      "Epoch 296/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2982 - accuracy: 0.8673 - val_loss: 0.3790 - val_accuracy: 0.9146\n",
      "Epoch 297/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.8704 - val_loss: 1.2439 - val_accuracy: 0.3780\n",
      "Epoch 298/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2882 - accuracy: 0.8827 - val_loss: 0.5637 - val_accuracy: 0.7683\n",
      "Epoch 299/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2725 - accuracy: 0.8951 - val_loss: 0.2218 - val_accuracy: 0.9268\n",
      "Epoch 300/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2804 - accuracy: 0.8858 - val_loss: 0.2521 - val_accuracy: 0.9268\n",
      "Epoch 301/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.8889 - val_loss: 0.1678 - val_accuracy: 0.9268\n",
      "Epoch 302/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3181 - accuracy: 0.8673 - val_loss: 0.3113 - val_accuracy: 0.9268\n",
      "Epoch 303/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2571 - accuracy: 0.9043 - val_loss: 1.1858 - val_accuracy: 0.4268\n",
      "Epoch 304/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.8611 - val_loss: 0.7489 - val_accuracy: 0.6829\n",
      "Epoch 305/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2856 - accuracy: 0.8796 - val_loss: 0.3042 - val_accuracy: 0.9268\n",
      "Epoch 306/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2814 - accuracy: 0.9074 - val_loss: 0.3931 - val_accuracy: 0.8902\n",
      "Epoch 307/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2691 - accuracy: 0.9074 - val_loss: 0.8169 - val_accuracy: 0.7439\n",
      "Epoch 308/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2785 - accuracy: 0.8858 - val_loss: 0.2700 - val_accuracy: 0.9268\n",
      "Epoch 309/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.7470 - val_accuracy: 0.6585\n",
      "Epoch 310/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2666 - accuracy: 0.8889 - val_loss: 0.2459 - val_accuracy: 0.9512\n",
      "Epoch 311/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8580 - val_loss: 0.3342 - val_accuracy: 0.8902\n",
      "Epoch 312/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2891 - accuracy: 0.8858 - val_loss: 0.5175 - val_accuracy: 0.8049\n",
      "Epoch 313/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2545 - accuracy: 0.9012 - val_loss: 0.8032 - val_accuracy: 0.6463\n",
      "Epoch 314/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8951 - val_loss: 0.3249 - val_accuracy: 0.9268\n",
      "Epoch 315/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2604 - accuracy: 0.9043 - val_loss: 0.3458 - val_accuracy: 0.9268\n",
      "Epoch 316/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.9043 - val_loss: 0.2947 - val_accuracy: 0.8902\n",
      "Epoch 317/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2610 - accuracy: 0.8981 - val_loss: 0.2789 - val_accuracy: 0.9268\n",
      "Epoch 318/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2703 - accuracy: 0.8951 - val_loss: 0.2051 - val_accuracy: 0.9268\n",
      "Epoch 319/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2801 - accuracy: 0.8951 - val_loss: 0.4722 - val_accuracy: 0.8415\n",
      "Epoch 320/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.8858 - val_loss: 1.8253 - val_accuracy: 0.2805\n",
      "Epoch 321/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2939 - accuracy: 0.8642 - val_loss: 0.5335 - val_accuracy: 0.8171\n",
      "Epoch 322/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.9167 - val_loss: 0.2640 - val_accuracy: 0.9268\n",
      "Epoch 323/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2586 - accuracy: 0.8889 - val_loss: 0.5649 - val_accuracy: 0.8049\n",
      "Epoch 324/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.9167 - val_loss: 0.8649 - val_accuracy: 0.6585\n",
      "Epoch 325/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2527 - accuracy: 0.9043 - val_loss: 0.7669 - val_accuracy: 0.6707\n",
      "Epoch 326/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2528 - accuracy: 0.9105 - val_loss: 0.8327 - val_accuracy: 0.7195\n",
      "Epoch 327/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.8981 - val_loss: 0.7450 - val_accuracy: 0.7317\n",
      "Epoch 328/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2355 - accuracy: 0.9105 - val_loss: 0.1205 - val_accuracy: 0.9756\n",
      "Epoch 329/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.8580 - val_loss: 0.9858 - val_accuracy: 0.6341\n",
      "Epoch 330/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.8981 - val_loss: 0.4703 - val_accuracy: 0.8659\n",
      "Epoch 331/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2312 - accuracy: 0.9074 - val_loss: 0.3134 - val_accuracy: 0.9268\n",
      "Epoch 332/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2977 - accuracy: 0.8735 - val_loss: 0.5711 - val_accuracy: 0.8415\n",
      "Epoch 333/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.9074 - val_loss: 0.5453 - val_accuracy: 0.8171\n",
      "Epoch 334/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2277 - accuracy: 0.9228 - val_loss: 1.5799 - val_accuracy: 0.3537\n",
      "Epoch 335/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8858 - val_loss: 0.5636 - val_accuracy: 0.8171\n",
      "Epoch 336/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2298 - accuracy: 0.9228 - val_loss: 0.4369 - val_accuracy: 0.8902\n",
      "Epoch 337/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2427 - accuracy: 0.9228 - val_loss: 0.3259 - val_accuracy: 0.8902\n",
      "Epoch 338/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2518 - accuracy: 0.9228 - val_loss: 0.3767 - val_accuracy: 0.8902\n",
      "Epoch 339/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.9043 - val_loss: 0.9616 - val_accuracy: 0.6829\n",
      "Epoch 340/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2792 - accuracy: 0.8796 - val_loss: 1.2719 - val_accuracy: 0.3902\n",
      "Epoch 341/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.9012 - val_loss: 2.5546 - val_accuracy: 0.2317\n",
      "Epoch 342/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8951 - val_loss: 0.2617 - val_accuracy: 0.8902\n",
      "Epoch 343/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2624 - accuracy: 0.8951 - val_loss: 0.3699 - val_accuracy: 0.8537\n",
      "Epoch 344/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9228 - val_loss: 1.2277 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.9136 - val_loss: 0.7584 - val_accuracy: 0.7195\n",
      "Epoch 346/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2421 - accuracy: 0.9012 - val_loss: 1.0896 - val_accuracy: 0.4634\n",
      "Epoch 347/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2387 - accuracy: 0.8920 - val_loss: 0.8487 - val_accuracy: 0.7073\n",
      "Epoch 348/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2261 - accuracy: 0.9136 - val_loss: 0.4880 - val_accuracy: 0.8780\n",
      "Epoch 349/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.9198 - val_loss: 0.3616 - val_accuracy: 0.8902\n",
      "Epoch 350/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3935 - val_accuracy: 0.8902\n",
      "Epoch 351/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.9167 - val_loss: 0.4283 - val_accuracy: 0.8902\n",
      "Epoch 352/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.9105 - val_loss: 0.3251 - val_accuracy: 0.9268\n",
      "Epoch 353/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2325 - accuracy: 0.9074 - val_loss: 0.3254 - val_accuracy: 0.8902\n",
      "Epoch 354/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2201 - accuracy: 0.9198 - val_loss: 0.7720 - val_accuracy: 0.7073\n",
      "Epoch 355/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2271 - accuracy: 0.9136 - val_loss: 0.4768 - val_accuracy: 0.8780\n",
      "Epoch 356/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2152 - accuracy: 0.9290 - val_loss: 1.5761 - val_accuracy: 0.3780\n",
      "Epoch 357/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2639 - accuracy: 0.9105 - val_loss: 0.6111 - val_accuracy: 0.8780\n",
      "Epoch 358/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2234 - accuracy: 0.9198 - val_loss: 0.3914 - val_accuracy: 0.9146\n",
      "Epoch 359/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2543 - accuracy: 0.9074 - val_loss: 0.7955 - val_accuracy: 0.6220\n",
      "Epoch 360/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 0.9074 - val_loss: 0.3371 - val_accuracy: 0.9268\n",
      "Epoch 361/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2286 - accuracy: 0.9228 - val_loss: 0.5123 - val_accuracy: 0.8293\n",
      "Epoch 362/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.8920 - val_loss: 0.5595 - val_accuracy: 0.8049\n",
      "Epoch 363/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9167 - val_loss: 0.4779 - val_accuracy: 0.8171\n",
      "Epoch 364/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2311 - accuracy: 0.9074 - val_loss: 0.1879 - val_accuracy: 0.9390\n",
      "Epoch 365/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2823 - accuracy: 0.8951 - val_loss: 0.4550 - val_accuracy: 0.8415\n",
      "Epoch 366/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2195 - accuracy: 0.9259 - val_loss: 0.9311 - val_accuracy: 0.6707\n",
      "Epoch 367/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2092 - accuracy: 0.9198 - val_loss: 0.3272 - val_accuracy: 0.9268\n",
      "Epoch 368/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2195 - accuracy: 0.9198 - val_loss: 0.3306 - val_accuracy: 0.9268\n",
      "Epoch 369/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2517 - accuracy: 0.8981 - val_loss: 1.0363 - val_accuracy: 0.5244\n",
      "Epoch 370/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.8981 - val_loss: 0.4822 - val_accuracy: 0.8537\n",
      "Epoch 371/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9043 - val_loss: 0.3150 - val_accuracy: 0.9268\n",
      "Epoch 372/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2159 - accuracy: 0.9352 - val_loss: 0.6426 - val_accuracy: 0.8049\n",
      "Epoch 373/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2394 - accuracy: 0.9043 - val_loss: 0.2163 - val_accuracy: 0.9268\n",
      "Epoch 374/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2335 - accuracy: 0.9198 - val_loss: 1.1767 - val_accuracy: 0.4390\n",
      "Epoch 375/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2209 - accuracy: 0.9198 - val_loss: 0.6641 - val_accuracy: 0.8049\n",
      "Epoch 376/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2061 - accuracy: 0.9383 - val_loss: 0.4454 - val_accuracy: 0.8902\n",
      "Epoch 377/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2133 - accuracy: 0.9043 - val_loss: 0.2273 - val_accuracy: 0.9390\n",
      "Epoch 378/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.9167 - val_loss: 0.4798 - val_accuracy: 0.8902\n",
      "Epoch 379/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9198 - val_loss: 0.2815 - val_accuracy: 0.9268\n",
      "Epoch 380/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2558 - accuracy: 0.8889 - val_loss: 0.3450 - val_accuracy: 0.8902\n",
      "Epoch 381/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2217 - accuracy: 0.9074 - val_loss: 0.4220 - val_accuracy: 0.8780\n",
      "Epoch 382/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 0.9105 - val_loss: 0.7942 - val_accuracy: 0.6585\n",
      "Epoch 383/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2024 - accuracy: 0.9290 - val_loss: 0.5297 - val_accuracy: 0.8415\n",
      "Epoch 384/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2391 - accuracy: 0.9012 - val_loss: 2.4273 - val_accuracy: 0.2073\n",
      "Epoch 385/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3070 - accuracy: 0.8858 - val_loss: 0.7008 - val_accuracy: 0.7561\n",
      "Epoch 386/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2025 - accuracy: 0.9228 - val_loss: 0.4912 - val_accuracy: 0.8537\n",
      "Epoch 387/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2102 - accuracy: 0.9321 - val_loss: 0.7469 - val_accuracy: 0.7439\n",
      "Epoch 388/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2266 - accuracy: 0.9136 - val_loss: 1.0167 - val_accuracy: 0.6463\n",
      "Epoch 389/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2083 - accuracy: 0.9290 - val_loss: 2.2058 - val_accuracy: 0.3780\n",
      "Epoch 390/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2554 - accuracy: 0.9228 - val_loss: 0.5506 - val_accuracy: 0.8780\n",
      "Epoch 391/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1963 - accuracy: 0.9383 - val_loss: 2.0912 - val_accuracy: 0.2439\n",
      "Epoch 392/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3401 - accuracy: 0.8611 - val_loss: 0.4485 - val_accuracy: 0.8780\n",
      "Epoch 393/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2057 - accuracy: 0.9259 - val_loss: 0.4056 - val_accuracy: 0.8902\n",
      "Epoch 394/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2135 - accuracy: 0.9228 - val_loss: 1.2872 - val_accuracy: 0.4512\n",
      "Epoch 395/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.9259 - val_loss: 0.7867 - val_accuracy: 0.7317\n",
      "Epoch 396/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1865 - accuracy: 0.9352 - val_loss: 0.3677 - val_accuracy: 0.8902\n",
      "Epoch 397/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2045 - accuracy: 0.9290 - val_loss: 0.4833 - val_accuracy: 0.8780\n",
      "Epoch 398/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1811 - accuracy: 0.9321 - val_loss: 0.4281 - val_accuracy: 0.8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1876 - accuracy: 0.9259 - val_loss: 0.3823 - val_accuracy: 0.8902\n",
      "Epoch 400/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1937 - accuracy: 0.9352 - val_loss: 0.5020 - val_accuracy: 0.8780\n",
      "Epoch 401/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1997 - accuracy: 0.9290 - val_loss: 0.5845 - val_accuracy: 0.8415\n",
      "Epoch 402/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1932 - accuracy: 0.9259 - val_loss: 0.5626 - val_accuracy: 0.8537\n",
      "Epoch 403/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9228 - val_loss: 0.5660 - val_accuracy: 0.8780\n",
      "Epoch 404/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.9074 - val_loss: 0.5994 - val_accuracy: 0.8415\n",
      "Epoch 405/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1817 - accuracy: 0.9352 - val_loss: 0.4017 - val_accuracy: 0.8780\n",
      "Epoch 406/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2131 - accuracy: 0.9167 - val_loss: 0.6398 - val_accuracy: 0.8415\n",
      "Epoch 407/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1806 - accuracy: 0.9290 - val_loss: 0.4059 - val_accuracy: 0.8902\n",
      "Epoch 408/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9043 - val_loss: 0.3810 - val_accuracy: 0.8902\n",
      "Epoch 409/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1728 - accuracy: 0.9383 - val_loss: 0.4294 - val_accuracy: 0.8780\n",
      "Epoch 410/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1793 - accuracy: 0.9383 - val_loss: 1.7435 - val_accuracy: 0.2439\n",
      "Epoch 411/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2672 - accuracy: 0.8920 - val_loss: 0.5795 - val_accuracy: 0.8537\n",
      "Epoch 412/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.9290 - val_loss: 0.2515 - val_accuracy: 0.9390\n",
      "Epoch 413/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9136 - val_loss: 0.6943 - val_accuracy: 0.7805\n",
      "Epoch 414/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.9352 - val_loss: 0.4388 - val_accuracy: 0.8902\n",
      "Epoch 415/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1728 - accuracy: 0.9352 - val_loss: 0.1336 - val_accuracy: 0.9634\n",
      "Epoch 416/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3678 - accuracy: 0.8395 - val_loss: 0.1397 - val_accuracy: 0.9390\n",
      "Epoch 417/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3035 - accuracy: 0.8673 - val_loss: 1.3408 - val_accuracy: 0.4146\n",
      "Epoch 418/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2095 - accuracy: 0.9136 - val_loss: 0.3335 - val_accuracy: 0.9268\n",
      "Epoch 419/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1754 - accuracy: 0.9321 - val_loss: 1.7762 - val_accuracy: 0.3171\n",
      "Epoch 420/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9105 - val_loss: 0.4413 - val_accuracy: 0.8780\n",
      "Epoch 421/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9136 - val_loss: 1.3416 - val_accuracy: 0.4756\n",
      "Epoch 422/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.9321 - val_loss: 0.3143 - val_accuracy: 0.8902\n",
      "Epoch 423/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2302 - accuracy: 0.9012 - val_loss: 0.5307 - val_accuracy: 0.8537\n",
      "Epoch 424/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1977 - accuracy: 0.9105 - val_loss: 0.3927 - val_accuracy: 0.8902\n",
      "Epoch 425/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1888 - accuracy: 0.9198 - val_loss: 1.0907 - val_accuracy: 0.5488\n",
      "Epoch 426/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9228 - val_loss: 0.5296 - val_accuracy: 0.8780\n",
      "Epoch 427/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1668 - accuracy: 0.9352 - val_loss: 0.5286 - val_accuracy: 0.8537\n",
      "Epoch 428/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9383 - val_loss: 0.4956 - val_accuracy: 0.8415\n",
      "Epoch 429/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9352 - val_loss: 0.3953 - val_accuracy: 0.8780\n",
      "Epoch 430/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9321 - val_loss: 0.3648 - val_accuracy: 0.9024\n",
      "Epoch 431/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9259 - val_loss: 1.1613 - val_accuracy: 0.5488\n",
      "Epoch 432/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2108 - accuracy: 0.9105 - val_loss: 0.3657 - val_accuracy: 0.9024\n",
      "Epoch 433/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 2.0796 - val_accuracy: 0.2561\n",
      "Epoch 434/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2875 - accuracy: 0.8796 - val_loss: 0.3771 - val_accuracy: 0.9146\n",
      "Epoch 435/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1665 - accuracy: 0.9475 - val_loss: 1.5777 - val_accuracy: 0.4024\n",
      "Epoch 436/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9074 - val_loss: 0.5577 - val_accuracy: 0.8780\n",
      "Epoch 437/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.4365 - val_accuracy: 0.8780\n",
      "Epoch 438/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1660 - accuracy: 0.9414 - val_loss: 0.5248 - val_accuracy: 0.8780\n",
      "Epoch 439/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1727 - accuracy: 0.9321 - val_loss: 0.4501 - val_accuracy: 0.8780\n",
      "Epoch 440/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1801 - accuracy: 0.9259 - val_loss: 5.4931 - val_accuracy: 0.1341\n",
      "Epoch 441/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.8611 - val_loss: 0.4284 - val_accuracy: 0.8780\n",
      "Epoch 442/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1713 - accuracy: 0.9383 - val_loss: 0.2682 - val_accuracy: 0.9512\n",
      "Epoch 443/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1906 - accuracy: 0.9352 - val_loss: 0.4832 - val_accuracy: 0.8780\n",
      "Epoch 444/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1571 - accuracy: 0.9475 - val_loss: 0.8880 - val_accuracy: 0.6951\n",
      "Epoch 445/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2025 - accuracy: 0.8981 - val_loss: 0.6915 - val_accuracy: 0.8049\n",
      "Epoch 446/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1622 - accuracy: 0.9383 - val_loss: 0.3668 - val_accuracy: 0.8902\n",
      "Epoch 447/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1605 - accuracy: 0.9414 - val_loss: 0.4508 - val_accuracy: 0.8780\n",
      "Epoch 448/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9383 - val_loss: 0.3819 - val_accuracy: 0.8902\n",
      "Epoch 449/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9383 - val_loss: 0.4320 - val_accuracy: 0.8780\n",
      "Epoch 450/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1572 - accuracy: 0.9444 - val_loss: 1.4952 - val_accuracy: 0.3537\n",
      "Epoch 451/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1796 - accuracy: 0.9290 - val_loss: 0.4553 - val_accuracy: 0.8780\n",
      "Epoch 452/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1450 - accuracy: 0.9414 - val_loss: 0.1672 - val_accuracy: 0.9512\n",
      "Epoch 453/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2391 - accuracy: 0.8889 - val_loss: 0.1510 - val_accuracy: 0.9512\n",
      "Epoch 454/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2539 - accuracy: 0.8981 - val_loss: 0.3154 - val_accuracy: 0.9268\n",
      "Epoch 455/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9290 - val_loss: 0.3015 - val_accuracy: 0.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.9321 - val_loss: 0.5425 - val_accuracy: 0.8780\n",
      "Epoch 457/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.9475 - val_loss: 0.3274 - val_accuracy: 0.9512\n",
      "Epoch 458/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9228 - val_loss: 0.4950 - val_accuracy: 0.8537\n",
      "Epoch 459/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9444 - val_loss: 0.4890 - val_accuracy: 0.8537\n",
      "Epoch 460/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1558 - accuracy: 0.9321 - val_loss: 0.3869 - val_accuracy: 0.9024\n",
      "Epoch 461/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9537 - val_loss: 0.4032 - val_accuracy: 0.9024\n",
      "Epoch 462/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9506 - val_loss: 0.3845 - val_accuracy: 0.8902\n",
      "Epoch 463/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1514 - accuracy: 0.9414 - val_loss: 0.5486 - val_accuracy: 0.8780\n",
      "Epoch 464/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1579 - accuracy: 0.9383 - val_loss: 0.2617 - val_accuracy: 0.9512\n",
      "Epoch 465/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1756 - accuracy: 0.9321 - val_loss: 1.1596 - val_accuracy: 0.6098\n",
      "Epoch 466/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9290 - val_loss: 0.4113 - val_accuracy: 0.9146\n",
      "Epoch 467/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1607 - accuracy: 0.9475 - val_loss: 0.1829 - val_accuracy: 0.9634\n",
      "Epoch 468/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.8827 - val_loss: 0.3563 - val_accuracy: 0.9024\n",
      "Epoch 469/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.9352 - val_loss: 0.3223 - val_accuracy: 0.9512\n",
      "Epoch 470/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.9599 - val_loss: 0.5322 - val_accuracy: 0.9024\n",
      "Epoch 471/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2016 - accuracy: 0.9259 - val_loss: 0.7248 - val_accuracy: 0.8293\n",
      "Epoch 472/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9414 - val_loss: 1.0999 - val_accuracy: 0.6098\n",
      "Epoch 473/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9352 - val_loss: 0.8999 - val_accuracy: 0.7073\n",
      "Epoch 474/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1806 - accuracy: 0.9167 - val_loss: 0.4250 - val_accuracy: 0.8902\n",
      "Epoch 475/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.9414 - val_loss: 0.6691 - val_accuracy: 0.8171\n",
      "Epoch 476/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1514 - accuracy: 0.9444 - val_loss: 2.2791 - val_accuracy: 0.2805\n",
      "Epoch 477/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9259 - val_loss: 1.2870 - val_accuracy: 0.5976\n",
      "Epoch 478/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.8735 - val_loss: 0.6016 - val_accuracy: 0.8293\n",
      "Epoch 479/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.9414 - val_loss: 0.3315 - val_accuracy: 0.9024\n",
      "Epoch 480/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1669 - accuracy: 0.9414 - val_loss: 1.6493 - val_accuracy: 0.4268\n",
      "Epoch 481/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1818 - accuracy: 0.9228 - val_loss: 0.7008 - val_accuracy: 0.8415\n",
      "Epoch 482/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9475 - val_loss: 0.4881 - val_accuracy: 0.8902\n",
      "Epoch 483/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.9444 - val_loss: 0.2545 - val_accuracy: 0.9390\n",
      "Epoch 484/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9259 - val_loss: 0.3835 - val_accuracy: 0.9024\n",
      "Epoch 485/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.9599 - val_loss: 1.3850 - val_accuracy: 0.5122\n",
      "Epoch 486/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8611 - val_loss: 0.1387 - val_accuracy: 0.9512\n",
      "Epoch 487/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2791 - accuracy: 0.8889 - val_loss: 0.5518 - val_accuracy: 0.8537\n",
      "Epoch 488/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.9444 - val_loss: 0.6231 - val_accuracy: 0.8537\n",
      "Epoch 489/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1405 - accuracy: 0.9444 - val_loss: 0.9618 - val_accuracy: 0.6220\n",
      "Epoch 490/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1549 - accuracy: 0.9321 - val_loss: 0.4754 - val_accuracy: 0.8780\n",
      "Epoch 491/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9568 - val_loss: 1.2342 - val_accuracy: 0.5854\n",
      "Epoch 492/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1795 - accuracy: 0.9290 - val_loss: 0.5480 - val_accuracy: 0.8293\n",
      "Epoch 493/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9444 - val_loss: 0.9345 - val_accuracy: 0.6829\n",
      "Epoch 494/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.9290 - val_loss: 0.4367 - val_accuracy: 0.8902\n",
      "Epoch 495/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.9506 - val_loss: 0.4682 - val_accuracy: 0.8902\n",
      "Epoch 496/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1504 - accuracy: 0.9537 - val_loss: 0.2959 - val_accuracy: 0.9512\n",
      "Epoch 497/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9444 - val_loss: 0.7471 - val_accuracy: 0.7561\n",
      "Epoch 498/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.9475 - val_loss: 0.4430 - val_accuracy: 0.8780\n",
      "Epoch 499/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9475 - val_loss: 0.4952 - val_accuracy: 0.9024\n",
      "Epoch 500/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9506 - val_loss: 0.5092 - val_accuracy: 0.9024\n",
      "Epoch 501/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.9506 - val_loss: 1.0788 - val_accuracy: 0.7073\n",
      "Epoch 502/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.9568 - val_loss: 0.5345 - val_accuracy: 0.8780\n",
      "Epoch 503/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9506 - val_loss: 0.4128 - val_accuracy: 0.9024\n",
      "Epoch 504/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9568 - val_loss: 1.4105 - val_accuracy: 0.4634\n",
      "Epoch 505/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9444 - val_loss: 0.6423 - val_accuracy: 0.8659\n",
      "Epoch 506/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.9537 - val_loss: 0.4919 - val_accuracy: 0.8780\n",
      "Epoch 507/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9568 - val_loss: 0.3332 - val_accuracy: 0.9146\n",
      "Epoch 508/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1239 - accuracy: 0.9660 - val_loss: 0.4356 - val_accuracy: 0.9146\n",
      "Epoch 509/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1226 - accuracy: 0.9537 - val_loss: 0.4430 - val_accuracy: 0.9024\n",
      "Epoch 510/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.9599 - val_loss: 0.6291 - val_accuracy: 0.8902\n",
      "Epoch 511/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9691 - val_loss: 0.5202 - val_accuracy: 0.9024\n",
      "Epoch 512/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9691 - val_loss: 0.6868 - val_accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1213 - accuracy: 0.9537 - val_loss: 0.4976 - val_accuracy: 0.8659\n",
      "Epoch 514/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9444 - val_loss: 0.5717 - val_accuracy: 0.8902\n",
      "Epoch 515/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1137 - accuracy: 0.9660 - val_loss: 0.7472 - val_accuracy: 0.8049\n",
      "Epoch 516/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1108 - accuracy: 0.9568 - val_loss: 0.5627 - val_accuracy: 0.8780\n",
      "Epoch 517/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1185 - accuracy: 0.9568 - val_loss: 0.5257 - val_accuracy: 0.8537\n",
      "Epoch 518/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9568 - val_loss: 0.3514 - val_accuracy: 0.9024\n",
      "Epoch 519/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.9414 - val_loss: 2.5803 - val_accuracy: 0.3049\n",
      "Epoch 520/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3094 - accuracy: 0.8981 - val_loss: 0.2586 - val_accuracy: 0.9512\n",
      "Epoch 521/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8611 - val_loss: 0.4026 - val_accuracy: 0.9024\n",
      "Epoch 522/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9630 - val_loss: 0.5618 - val_accuracy: 0.8659\n",
      "Epoch 523/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.9506 - val_loss: 0.8020 - val_accuracy: 0.7439\n",
      "Epoch 524/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.9167 - val_loss: 0.3857 - val_accuracy: 0.9146\n",
      "Epoch 525/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1173 - accuracy: 0.9506 - val_loss: 0.5013 - val_accuracy: 0.9024\n",
      "Epoch 526/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9753 - val_loss: 0.3716 - val_accuracy: 0.9146\n",
      "Epoch 527/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9444 - val_loss: 0.3488 - val_accuracy: 0.9146\n",
      "Epoch 528/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1321 - accuracy: 0.9414 - val_loss: 0.5931 - val_accuracy: 0.8780\n",
      "Epoch 529/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9722 - val_loss: 0.2985 - val_accuracy: 0.9146\n",
      "Epoch 530/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1310 - accuracy: 0.9568 - val_loss: 0.9004 - val_accuracy: 0.7805\n",
      "Epoch 531/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.9506 - val_loss: 0.3873 - val_accuracy: 0.9024\n",
      "Epoch 532/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.9599 - val_loss: 0.4802 - val_accuracy: 0.9024\n",
      "Epoch 533/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 0.9660 - val_loss: 0.4621 - val_accuracy: 0.9024\n",
      "Epoch 534/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9599 - val_loss: 0.4533 - val_accuracy: 0.8902\n",
      "Epoch 535/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1160 - accuracy: 0.9506 - val_loss: 0.4452 - val_accuracy: 0.9024\n",
      "Epoch 536/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1188 - accuracy: 0.9568 - val_loss: 0.7001 - val_accuracy: 0.8659\n",
      "Epoch 537/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1231 - accuracy: 0.9506 - val_loss: 0.5267 - val_accuracy: 0.8902\n",
      "Epoch 538/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1049 - accuracy: 0.9660 - val_loss: 0.5482 - val_accuracy: 0.8902\n",
      "Epoch 539/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9321 - val_loss: 0.9730 - val_accuracy: 0.7439\n",
      "Epoch 540/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1170 - accuracy: 0.9506 - val_loss: 0.8938 - val_accuracy: 0.7683\n",
      "Epoch 541/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9660 - val_loss: 0.4621 - val_accuracy: 0.9024\n",
      "Epoch 542/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.9784 - val_loss: 0.4841 - val_accuracy: 0.8902\n",
      "Epoch 543/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9506 - val_loss: 0.3552 - val_accuracy: 0.9024\n",
      "Epoch 544/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1085 - accuracy: 0.9568 - val_loss: 0.2977 - val_accuracy: 0.9390\n",
      "Epoch 545/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.9630 - val_loss: 0.4478 - val_accuracy: 0.9146\n",
      "Epoch 546/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9660 - val_loss: 0.4895 - val_accuracy: 0.8902\n",
      "Epoch 547/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1065 - accuracy: 0.9599 - val_loss: 0.4708 - val_accuracy: 0.9024\n",
      "Epoch 548/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9568 - val_loss: 0.4950 - val_accuracy: 0.9024\n",
      "Epoch 549/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.9722 - val_loss: 0.5403 - val_accuracy: 0.9024\n",
      "Epoch 550/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9722 - val_loss: 0.4205 - val_accuracy: 0.9024\n",
      "Epoch 551/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1153 - accuracy: 0.9537 - val_loss: 0.4862 - val_accuracy: 0.9024\n",
      "Epoch 552/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9691 - val_loss: 0.3321 - val_accuracy: 0.9390\n",
      "Epoch 553/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1211 - accuracy: 0.9506 - val_loss: 0.3977 - val_accuracy: 0.9268\n",
      "Epoch 554/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9599 - val_loss: 0.8839 - val_accuracy: 0.7805\n",
      "Epoch 555/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9599 - val_loss: 0.4499 - val_accuracy: 0.9024\n",
      "Epoch 556/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.9691 - val_loss: 0.3423 - val_accuracy: 0.9146\n",
      "Epoch 557/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9475 - val_loss: 0.4334 - val_accuracy: 0.9024\n",
      "Epoch 558/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1564 - accuracy: 0.9352 - val_loss: 1.8269 - val_accuracy: 0.4878\n",
      "Epoch 559/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6214 - accuracy: 0.7901 - val_loss: 0.7865 - val_accuracy: 0.8171\n",
      "Epoch 560/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1288 - accuracy: 0.9475 - val_loss: 0.4573 - val_accuracy: 0.9024\n",
      "Epoch 561/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.9599 - val_loss: 0.3216 - val_accuracy: 0.9146\n",
      "Epoch 562/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9537 - val_loss: 0.4508 - val_accuracy: 0.8537\n",
      "Epoch 563/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1073 - accuracy: 0.9537 - val_loss: 0.4887 - val_accuracy: 0.8902\n",
      "Epoch 564/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1062 - accuracy: 0.9660 - val_loss: 5.5818 - val_accuracy: 0.1463\n",
      "Epoch 565/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8920 - val_loss: 0.3486 - val_accuracy: 0.9024\n",
      "Epoch 566/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1260 - accuracy: 0.9506 - val_loss: 0.4777 - val_accuracy: 0.9024\n",
      "Epoch 567/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1167 - accuracy: 0.9599 - val_loss: 0.4781 - val_accuracy: 0.8902\n",
      "Epoch 568/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9691 - val_loss: 0.5593 - val_accuracy: 0.8902\n",
      "Epoch 569/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9630 - val_loss: 0.3692 - val_accuracy: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0975 - accuracy: 0.9722 - val_loss: 0.3551 - val_accuracy: 0.9146\n",
      "Epoch 571/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.9630 - val_loss: 0.6190 - val_accuracy: 0.8659\n",
      "Epoch 572/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9753 - val_loss: 4.7505 - val_accuracy: 0.2195\n",
      "Epoch 573/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3612 - accuracy: 0.8981 - val_loss: 1.5530 - val_accuracy: 0.4634\n",
      "Epoch 574/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1952 - accuracy: 0.9167 - val_loss: 0.5469 - val_accuracy: 0.9024\n",
      "Epoch 575/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9660 - val_loss: 0.5658 - val_accuracy: 0.8902\n",
      "Epoch 576/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 0.9660 - val_loss: 0.6317 - val_accuracy: 0.8902\n",
      "Epoch 577/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0917 - accuracy: 0.9722 - val_loss: 0.4699 - val_accuracy: 0.9024\n",
      "Epoch 578/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9599 - val_loss: 0.4502 - val_accuracy: 0.8902\n",
      "Epoch 579/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0959 - accuracy: 0.9691 - val_loss: 0.4499 - val_accuracy: 0.9024\n",
      "Epoch 580/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0881 - accuracy: 0.9753 - val_loss: 0.5255 - val_accuracy: 0.9024\n",
      "Epoch 581/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9753 - val_loss: 0.6650 - val_accuracy: 0.8780\n",
      "Epoch 582/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9660 - val_loss: 0.8270 - val_accuracy: 0.7927\n",
      "Epoch 583/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.9660 - val_loss: 3.6911 - val_accuracy: 0.3293\n",
      "Epoch 584/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2795 - accuracy: 0.9198 - val_loss: 0.3373 - val_accuracy: 0.9146\n",
      "Epoch 585/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9660 - val_loss: 0.4788 - val_accuracy: 0.8902\n",
      "Epoch 586/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9660 - val_loss: 0.4072 - val_accuracy: 0.9024\n",
      "Epoch 587/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1050 - accuracy: 0.9630 - val_loss: 0.7910 - val_accuracy: 0.8537\n",
      "Epoch 588/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0913 - accuracy: 0.9660 - val_loss: 1.3325 - val_accuracy: 0.6341\n",
      "Epoch 589/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.9352 - val_loss: 0.4992 - val_accuracy: 0.9024\n",
      "Epoch 590/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9815 - val_loss: 0.3724 - val_accuracy: 0.9146\n",
      "Epoch 591/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9753 - val_loss: 0.0774 - val_accuracy: 0.9756\n",
      "Epoch 592/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.8920 - val_loss: 0.7627 - val_accuracy: 0.8659\n",
      "Epoch 593/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9599 - val_loss: 0.5004 - val_accuracy: 0.9024\n",
      "Epoch 594/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0940 - accuracy: 0.9691 - val_loss: 0.8288 - val_accuracy: 0.8171\n",
      "Epoch 595/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9753 - val_loss: 4.0212 - val_accuracy: 0.2073\n",
      "Epoch 596/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2356 - accuracy: 0.9167 - val_loss: 0.7705 - val_accuracy: 0.8049\n",
      "Epoch 597/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9722 - val_loss: 0.4860 - val_accuracy: 0.9024\n",
      "Epoch 598/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9784 - val_loss: 0.5037 - val_accuracy: 0.9024\n",
      "Epoch 599/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9753 - val_loss: 0.3059 - val_accuracy: 0.9390\n",
      "Epoch 600/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9660 - val_loss: 0.3424 - val_accuracy: 0.9512\n",
      "Epoch 601/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9722 - val_loss: 0.5827 - val_accuracy: 0.8902\n",
      "Epoch 602/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9691 - val_loss: 0.5945 - val_accuracy: 0.8902\n",
      "Epoch 603/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9691 - val_loss: 0.0958 - val_accuracy: 0.9512\n",
      "Epoch 604/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2588 - accuracy: 0.9352 - val_loss: 0.8494 - val_accuracy: 0.8293\n",
      "Epoch 605/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9660 - val_loss: 0.4363 - val_accuracy: 0.9146\n",
      "Epoch 606/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9630 - val_loss: 0.4683 - val_accuracy: 0.8902\n",
      "Epoch 607/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9691 - val_loss: 0.5400 - val_accuracy: 0.9024\n",
      "Epoch 608/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9722 - val_loss: 0.4868 - val_accuracy: 0.9024\n",
      "Epoch 609/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9691 - val_loss: 0.4263 - val_accuracy: 0.9024\n",
      "Epoch 610/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9691 - val_loss: 0.4886 - val_accuracy: 0.9024\n",
      "Epoch 611/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9691 - val_loss: 0.6792 - val_accuracy: 0.8171\n",
      "Epoch 612/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9630 - val_loss: 0.4252 - val_accuracy: 0.9024\n",
      "Epoch 613/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9753 - val_loss: 0.6988 - val_accuracy: 0.8537\n",
      "Epoch 614/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9660 - val_loss: 0.7928 - val_accuracy: 0.8537\n",
      "Epoch 615/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9537 - val_loss: 0.9304 - val_accuracy: 0.7805\n",
      "Epoch 616/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9691 - val_loss: 0.4626 - val_accuracy: 0.9024\n",
      "Epoch 617/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9691 - val_loss: 0.4481 - val_accuracy: 0.9024\n",
      "Epoch 618/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9630 - val_loss: 0.5729 - val_accuracy: 0.9024\n",
      "Epoch 619/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9753 - val_loss: 0.4624 - val_accuracy: 0.9024\n",
      "Epoch 620/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 0.9691 - val_loss: 0.6891 - val_accuracy: 0.8659\n",
      "Epoch 621/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9784 - val_loss: 0.0726 - val_accuracy: 0.9756\n",
      "Epoch 622/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.8426 - val_loss: 0.1101 - val_accuracy: 0.9512\n",
      "Epoch 623/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2119 - accuracy: 0.9228 - val_loss: 0.1975 - val_accuracy: 0.9512\n",
      "Epoch 624/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1556 - accuracy: 0.9321 - val_loss: 0.6165 - val_accuracy: 0.9024\n",
      "Epoch 625/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0917 - accuracy: 0.9722 - val_loss: 0.4390 - val_accuracy: 0.9146\n",
      "Epoch 626/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9537 - val_loss: 0.5800 - val_accuracy: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.5862 - val_accuracy: 0.9024\n",
      "Epoch 628/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 0.3949 - val_accuracy: 0.9512\n",
      "Epoch 629/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9815 - val_loss: 1.1450 - val_accuracy: 0.6341\n",
      "Epoch 630/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.9568 - val_loss: 0.5169 - val_accuracy: 0.9024\n",
      "Epoch 631/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9660 - val_loss: 0.3310 - val_accuracy: 0.9512\n",
      "Epoch 632/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9660 - val_loss: 0.5386 - val_accuracy: 0.9024\n",
      "Epoch 633/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.9691 - val_loss: 0.4307 - val_accuracy: 0.9024\n",
      "Epoch 634/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0814 - accuracy: 0.9753 - val_loss: 0.7558 - val_accuracy: 0.8293\n",
      "Epoch 635/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0851 - accuracy: 0.9660 - val_loss: 0.5153 - val_accuracy: 0.9024\n",
      "Epoch 636/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0730 - accuracy: 0.9815 - val_loss: 0.4068 - val_accuracy: 0.9146\n",
      "Epoch 637/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9660 - val_loss: 0.3269 - val_accuracy: 0.9512\n",
      "Epoch 638/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9475 - val_loss: 0.5670 - val_accuracy: 0.9024\n",
      "Epoch 639/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 0.9784 - val_loss: 0.8020 - val_accuracy: 0.8659\n",
      "Epoch 640/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0876 - accuracy: 0.9722 - val_loss: 0.4673 - val_accuracy: 0.8902\n",
      "Epoch 641/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9537 - val_loss: 0.4322 - val_accuracy: 0.9390\n",
      "Epoch 642/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 0.9660 - val_loss: 0.5084 - val_accuracy: 0.9024\n",
      "Epoch 643/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0718 - accuracy: 0.9784 - val_loss: 1.7318 - val_accuracy: 0.5854\n",
      "Epoch 644/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.8333 - val_loss: 0.6187 - val_accuracy: 0.9024\n",
      "Epoch 645/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9753 - val_loss: 0.4412 - val_accuracy: 0.9024\n",
      "Epoch 646/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9722 - val_loss: 0.2173 - val_accuracy: 0.9512\n",
      "Epoch 647/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.9352 - val_loss: 0.5183 - val_accuracy: 0.9024\n",
      "Epoch 648/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.9599 - val_loss: 0.4236 - val_accuracy: 0.9146\n",
      "Epoch 649/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9784 - val_loss: 0.5467 - val_accuracy: 0.9024\n",
      "Epoch 650/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0776 - accuracy: 0.9722 - val_loss: 0.4397 - val_accuracy: 0.9146\n",
      "Epoch 651/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.5156 - val_accuracy: 0.9146\n",
      "Epoch 652/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.6056 - val_accuracy: 0.9024\n",
      "Epoch 653/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0729 - accuracy: 0.9784 - val_loss: 0.4793 - val_accuracy: 0.9024\n",
      "Epoch 654/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0680 - accuracy: 0.9784 - val_loss: 0.4983 - val_accuracy: 0.9024\n",
      "Epoch 655/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9815 - val_loss: 0.7108 - val_accuracy: 0.8902\n",
      "Epoch 656/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9815 - val_loss: 0.7307 - val_accuracy: 0.8780\n",
      "Epoch 657/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9722 - val_loss: 0.5379 - val_accuracy: 0.9024\n",
      "Epoch 658/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.5824 - val_accuracy: 0.9024\n",
      "Epoch 659/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9846 - val_loss: 0.7172 - val_accuracy: 0.8780\n",
      "Epoch 660/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.4678 - val_accuracy: 0.9146\n",
      "Epoch 661/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1778 - accuracy: 0.9259 - val_loss: 1.2443 - val_accuracy: 0.6707\n",
      "Epoch 662/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1946 - accuracy: 0.9383 - val_loss: 0.5489 - val_accuracy: 0.9146\n",
      "Epoch 663/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 0.2368 - val_accuracy: 0.9512\n",
      "Epoch 664/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.9259 - val_loss: 0.5263 - val_accuracy: 0.9024\n",
      "Epoch 665/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9722 - val_loss: 0.6016 - val_accuracy: 0.8902\n",
      "Epoch 666/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9722 - val_loss: 0.4945 - val_accuracy: 0.9024\n",
      "Epoch 667/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 0.4315 - val_accuracy: 0.9146\n",
      "Epoch 668/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 0.9815 - val_loss: 0.4818 - val_accuracy: 0.9024\n",
      "Epoch 669/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.7108 - val_accuracy: 0.8902\n",
      "Epoch 670/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9784 - val_loss: 0.5946 - val_accuracy: 0.9024\n",
      "Epoch 671/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9753 - val_loss: 0.4280 - val_accuracy: 0.9146\n",
      "Epoch 672/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.9155 - val_accuracy: 0.8049\n",
      "Epoch 673/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9784 - val_loss: 0.6503 - val_accuracy: 0.8902\n",
      "Epoch 674/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9722 - val_loss: 0.4657 - val_accuracy: 0.9024\n",
      "Epoch 675/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0676 - accuracy: 0.9691 - val_loss: 0.4220 - val_accuracy: 0.9146\n",
      "Epoch 676/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9753 - val_loss: 6.0049 - val_accuracy: 0.2073\n",
      "Epoch 677/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.8951 - val_loss: 0.4379 - val_accuracy: 0.9146\n",
      "Epoch 678/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0805 - accuracy: 0.9691 - val_loss: 0.4299 - val_accuracy: 0.9024\n",
      "Epoch 679/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9753 - val_loss: 3.5271 - val_accuracy: 0.2561\n",
      "Epoch 680/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2419 - accuracy: 0.9352 - val_loss: 0.3789 - val_accuracy: 0.9024\n",
      "Epoch 681/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.5637 - val_accuracy: 0.9024\n",
      "Epoch 682/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9846 - val_loss: 0.3956 - val_accuracy: 0.9024\n",
      "Epoch 683/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9815 - val_loss: 0.5097 - val_accuracy: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9753 - val_loss: 0.6899 - val_accuracy: 0.9024\n",
      "Epoch 685/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.3717 - val_accuracy: 0.9512\n",
      "Epoch 686/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9722 - val_loss: 0.5808 - val_accuracy: 0.9024\n",
      "Epoch 687/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.5152 - val_accuracy: 0.9024\n",
      "Epoch 688/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9753 - val_loss: 1.0014 - val_accuracy: 0.8049\n",
      "Epoch 689/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9691 - val_loss: 0.5615 - val_accuracy: 0.9024\n",
      "Epoch 690/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.5088 - val_accuracy: 0.9024\n",
      "Epoch 691/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 0.9753 - val_loss: 0.6239 - val_accuracy: 0.9024\n",
      "Epoch 692/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9846 - val_loss: 1.0433 - val_accuracy: 0.7805\n",
      "Epoch 693/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.8951 - val_loss: 0.4691 - val_accuracy: 0.9024\n",
      "Epoch 694/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9784 - val_loss: 0.6039 - val_accuracy: 0.9024\n",
      "Epoch 695/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9753 - val_loss: 0.7644 - val_accuracy: 0.8659\n",
      "Epoch 696/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9722 - val_loss: 0.5891 - val_accuracy: 0.9024\n",
      "Epoch 697/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9846 - val_loss: 0.7654 - val_accuracy: 0.8780\n",
      "Epoch 698/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 0.0886 - val_accuracy: 0.9756\n",
      "Epoch 699/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.8642 - val_loss: 0.4622 - val_accuracy: 0.9146\n",
      "Epoch 700/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1276 - accuracy: 0.9444 - val_loss: 0.4527 - val_accuracy: 0.9146\n",
      "Epoch 701/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9722 - val_loss: 0.5292 - val_accuracy: 0.9024\n",
      "Epoch 702/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9753 - val_loss: 0.5546 - val_accuracy: 0.9024\n",
      "Epoch 703/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9753 - val_loss: 0.5022 - val_accuracy: 0.9146\n",
      "Epoch 704/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9537 - val_loss: 0.5979 - val_accuracy: 0.9024\n",
      "Epoch 705/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9630 - val_loss: 0.5883 - val_accuracy: 0.9024\n",
      "Epoch 706/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.6438 - val_accuracy: 0.9024\n",
      "Epoch 707/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9784 - val_loss: 0.5356 - val_accuracy: 0.9024\n",
      "Epoch 708/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9784 - val_loss: 0.5663 - val_accuracy: 0.9024\n",
      "Epoch 709/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.5920 - val_accuracy: 0.9024\n",
      "Epoch 710/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9846 - val_loss: 0.5276 - val_accuracy: 0.9024\n",
      "Epoch 711/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9784 - val_loss: 0.5935 - val_accuracy: 0.9024\n",
      "Epoch 712/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 0.2096 - val_accuracy: 0.9634\n",
      "Epoch 713/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8858 - val_loss: 0.7719 - val_accuracy: 0.8171\n",
      "Epoch 714/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9414 - val_loss: 0.5623 - val_accuracy: 0.8780\n",
      "Epoch 715/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9599 - val_loss: 0.6253 - val_accuracy: 0.8780\n",
      "Epoch 716/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9537 - val_loss: 0.3428 - val_accuracy: 0.9512\n",
      "Epoch 717/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9722 - val_loss: 0.5657 - val_accuracy: 0.9024\n",
      "Epoch 718/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9722 - val_loss: 0.5732 - val_accuracy: 0.9024\n",
      "Epoch 719/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9846 - val_loss: 0.5040 - val_accuracy: 0.9024\n",
      "Epoch 720/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9846 - val_loss: 0.5706 - val_accuracy: 0.9024\n",
      "Epoch 721/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 1.8275 - val_accuracy: 0.6951\n",
      "Epoch 722/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.9599 - val_loss: 0.6018 - val_accuracy: 0.9024\n",
      "Epoch 723/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9846 - val_loss: 0.4856 - val_accuracy: 0.9146\n",
      "Epoch 724/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.9722 - val_loss: 0.4729 - val_accuracy: 0.9146\n",
      "Epoch 725/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9784 - val_loss: 0.6888 - val_accuracy: 0.8537\n",
      "Epoch 726/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.4270 - val_accuracy: 0.9024\n",
      "Epoch 727/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9383 - val_loss: 0.3990 - val_accuracy: 0.9512\n",
      "Epoch 728/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1312 - accuracy: 0.9568 - val_loss: 0.4849 - val_accuracy: 0.9024\n",
      "Epoch 729/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9691 - val_loss: 0.8276 - val_accuracy: 0.8780\n",
      "Epoch 730/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9846 - val_loss: 0.6473 - val_accuracy: 0.9024\n",
      "Epoch 731/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9784 - val_loss: 0.9926 - val_accuracy: 0.8049\n",
      "Epoch 732/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.5022 - val_accuracy: 0.9024\n",
      "Epoch 733/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9846 - val_loss: 0.5766 - val_accuracy: 0.9024\n",
      "Epoch 734/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9846 - val_loss: 0.6060 - val_accuracy: 0.9024\n",
      "Epoch 735/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9753 - val_loss: 0.6903 - val_accuracy: 0.9024\n",
      "Epoch 736/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9815 - val_loss: 0.6322 - val_accuracy: 0.9024\n",
      "Epoch 737/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.5123 - val_accuracy: 0.9024\n",
      "Epoch 738/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.7040 - val_accuracy: 0.9024\n",
      "Epoch 739/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9877 - val_loss: 0.4511 - val_accuracy: 0.9146\n",
      "Epoch 740/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0759 - accuracy: 0.9630 - val_loss: 0.4001 - val_accuracy: 0.9146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0554 - accuracy: 0.9846 - val_loss: 0.7755 - val_accuracy: 0.9024\n",
      "Epoch 742/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 0.7329 - val_accuracy: 0.9024\n",
      "Epoch 743/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.6180 - val_accuracy: 0.9024\n",
      "Epoch 744/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.3866 - val_accuracy: 0.9146\n",
      "Epoch 745/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.5943 - val_accuracy: 0.9024\n",
      "Epoch 746/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.3539 - val_accuracy: 0.9512\n",
      "Epoch 747/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9660 - val_loss: 0.5306 - val_accuracy: 0.9024\n",
      "Epoch 748/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9815 - val_loss: 0.5248 - val_accuracy: 0.9024\n",
      "Epoch 749/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.6556 - val_accuracy: 0.9024\n",
      "Epoch 750/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9877 - val_loss: 0.4254 - val_accuracy: 0.9512\n",
      "Epoch 751/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9877 - val_loss: 1.0493 - val_accuracy: 0.8171\n",
      "Epoch 752/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9815 - val_loss: 0.8769 - val_accuracy: 0.8537\n",
      "Epoch 753/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9691 - val_loss: 0.5038 - val_accuracy: 0.9024\n",
      "Epoch 754/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.6644 - val_accuracy: 0.9024\n",
      "Epoch 755/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.6196 - val_accuracy: 0.9024\n",
      "Epoch 756/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9784 - val_loss: 0.6852 - val_accuracy: 0.9024\n",
      "Epoch 757/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.6275 - val_accuracy: 0.9024\n",
      "Epoch 758/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9877 - val_loss: 0.5864 - val_accuracy: 0.9024\n",
      "Epoch 759/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 0.5224 - val_accuracy: 0.9024\n",
      "Epoch 760/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 2.1108 - val_accuracy: 0.5610\n",
      "Epoch 761/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8981 - val_loss: 1.2189 - val_accuracy: 0.7317\n",
      "Epoch 762/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9722 - val_loss: 2.0528 - val_accuracy: 0.5610\n",
      "Epoch 763/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2341 - accuracy: 0.9167 - val_loss: 0.4700 - val_accuracy: 0.9146\n",
      "Epoch 764/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9815 - val_loss: 0.5690 - val_accuracy: 0.9024\n",
      "Epoch 765/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9877 - val_loss: 0.6015 - val_accuracy: 0.9024\n",
      "Epoch 766/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9938 - val_loss: 0.5819 - val_accuracy: 0.9024\n",
      "Epoch 767/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9660 - val_loss: 0.7713 - val_accuracy: 0.8902\n",
      "Epoch 768/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.4374 - val_accuracy: 0.9512\n",
      "Epoch 769/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 0.6577 - val_accuracy: 0.9024\n",
      "Epoch 770/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.5798 - val_accuracy: 0.9024\n",
      "Epoch 771/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9877 - val_loss: 0.6741 - val_accuracy: 0.9024\n",
      "Epoch 772/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 0.5504 - val_accuracy: 0.9024\n",
      "Epoch 773/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.6344 - val_accuracy: 0.9024\n",
      "Epoch 774/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.6169 - val_accuracy: 0.9024\n",
      "Epoch 775/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 0.7112 - val_accuracy: 0.9024\n",
      "Epoch 776/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.6024 - val_accuracy: 0.9024\n",
      "Epoch 777/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9938 - val_loss: 0.6177 - val_accuracy: 0.9024\n",
      "Epoch 778/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.6175 - val_accuracy: 0.9024\n",
      "Epoch 779/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9815 - val_loss: 0.5366 - val_accuracy: 0.9024\n",
      "Epoch 780/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9877 - val_loss: 1.7590 - val_accuracy: 0.6098\n",
      "Epoch 781/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.9414 - val_loss: 0.4148 - val_accuracy: 0.9512\n",
      "Epoch 782/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9877 - val_loss: 0.6480 - val_accuracy: 0.9024\n",
      "Epoch 783/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9877 - val_loss: 0.5526 - val_accuracy: 0.9024\n",
      "Epoch 784/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9938 - val_loss: 0.6400 - val_accuracy: 0.9024\n",
      "Epoch 785/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 1.0560 - val_accuracy: 0.8171\n",
      "Epoch 786/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.6369 - val_accuracy: 0.9024\n",
      "Epoch 787/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9815 - val_loss: 0.5812 - val_accuracy: 0.9024\n",
      "Epoch 788/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9938 - val_loss: 0.4318 - val_accuracy: 0.9512\n",
      "Epoch 789/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9784 - val_loss: 0.6148 - val_accuracy: 0.9024\n",
      "Epoch 790/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.5734 - val_accuracy: 0.9024\n",
      "Epoch 791/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9877 - val_loss: 0.6770 - val_accuracy: 0.9024\n",
      "Epoch 792/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9907 - val_loss: 0.6428 - val_accuracy: 0.9024\n",
      "Epoch 793/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9877 - val_loss: 0.2133 - val_accuracy: 0.9512\n",
      "Epoch 794/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2905 - accuracy: 0.8889 - val_loss: 1.1429 - val_accuracy: 0.7073\n",
      "Epoch 795/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9691 - val_loss: 0.5476 - val_accuracy: 0.9024\n",
      "Epoch 796/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.4875 - val_accuracy: 0.9024\n",
      "Epoch 797/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9846 - val_loss: 0.5523 - val_accuracy: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9907 - val_loss: 0.5640 - val_accuracy: 0.9024\n",
      "Epoch 799/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9907 - val_loss: 0.5119 - val_accuracy: 0.9024\n",
      "Epoch 800/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9877 - val_loss: 0.6100 - val_accuracy: 0.9024\n",
      "Epoch 801/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9907 - val_loss: 0.6954 - val_accuracy: 0.9024\n",
      "Epoch 802/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9877 - val_loss: 0.5221 - val_accuracy: 0.9024\n",
      "Epoch 803/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9907 - val_loss: 0.7096 - val_accuracy: 0.9024\n",
      "Epoch 804/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.7561 - val_accuracy: 0.8902\n",
      "Epoch 805/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.6322 - val_accuracy: 0.9024\n",
      "Epoch 806/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9938 - val_loss: 0.6106 - val_accuracy: 0.9024\n",
      "Epoch 807/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9907 - val_loss: 0.5609 - val_accuracy: 0.9024\n",
      "Epoch 808/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9938 - val_loss: 0.6290 - val_accuracy: 0.9024\n",
      "Epoch 809/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9907 - val_loss: 0.7386 - val_accuracy: 0.9024\n",
      "Epoch 810/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 0.6797 - val_accuracy: 0.9024\n",
      "Epoch 811/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9907 - val_loss: 0.6715 - val_accuracy: 0.9024\n",
      "Epoch 812/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9938 - val_loss: 0.7009 - val_accuracy: 0.9024\n",
      "Epoch 813/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9907 - val_loss: 0.6354 - val_accuracy: 0.9024\n",
      "Epoch 814/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.6174 - val_accuracy: 0.9024\n",
      "Epoch 815/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9907 - val_loss: 0.4792 - val_accuracy: 0.9024\n",
      "Epoch 816/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9877 - val_loss: 0.5515 - val_accuracy: 0.9024\n",
      "Epoch 817/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9907 - val_loss: 0.6182 - val_accuracy: 0.9024\n",
      "Epoch 818/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.5947 - val_accuracy: 0.9024\n",
      "Epoch 819/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 0.6819 - val_accuracy: 0.9024\n",
      "Epoch 820/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.5749 - val_accuracy: 0.9024\n",
      "Epoch 821/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9907 - val_loss: 0.5788 - val_accuracy: 0.9024\n",
      "Epoch 822/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9907 - val_loss: 0.7044 - val_accuracy: 0.9024\n",
      "Epoch 823/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9969 - val_loss: 0.7440 - val_accuracy: 0.9024\n",
      "Epoch 824/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.6927 - val_accuracy: 0.9024\n",
      "Epoch 825/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9877 - val_loss: 0.6457 - val_accuracy: 0.9024\n",
      "Epoch 826/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.7062 - val_accuracy: 0.9024\n",
      "Epoch 827/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 0.6443 - val_accuracy: 0.9024\n",
      "Epoch 828/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9938 - val_loss: 0.7674 - val_accuracy: 0.9024\n",
      "Epoch 829/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9877 - val_loss: 0.7633 - val_accuracy: 0.9024\n",
      "Epoch 830/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.6174 - val_accuracy: 0.9024\n",
      "Epoch 831/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9938 - val_loss: 0.5643 - val_accuracy: 0.9024\n",
      "Epoch 832/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.7303 - val_accuracy: 0.9024\n",
      "Epoch 833/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9815 - val_loss: 0.7242 - val_accuracy: 0.9024\n",
      "Epoch 834/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.7594 - val_accuracy: 0.9024\n",
      "Epoch 835/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9907 - val_loss: 0.8621 - val_accuracy: 0.8780\n",
      "Epoch 836/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.6991 - val_accuracy: 0.9024\n",
      "Epoch 837/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.6820 - val_accuracy: 0.9024\n",
      "Epoch 838/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9938 - val_loss: 0.5933 - val_accuracy: 0.9024\n",
      "Epoch 839/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9938 - val_loss: 0.6764 - val_accuracy: 0.9024\n",
      "Epoch 840/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9907 - val_loss: 0.6845 - val_accuracy: 0.9024\n",
      "Epoch 841/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9938 - val_loss: 0.7419 - val_accuracy: 0.9024\n",
      "Epoch 842/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9907 - val_loss: 0.7400 - val_accuracy: 0.9024\n",
      "Epoch 843/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9938 - val_loss: 0.6494 - val_accuracy: 0.9024\n",
      "Epoch 844/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 0.6450 - val_accuracy: 0.9024\n",
      "Epoch 845/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9907 - val_loss: 0.6846 - val_accuracy: 0.9024\n",
      "Epoch 846/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9877 - val_loss: 2.4580 - val_accuracy: 0.5610\n",
      "Epoch 847/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.8858 - val_loss: 0.0456 - val_accuracy: 0.9634\n",
      "Epoch 848/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0557 - accuracy: 0.7191 - val_loss: 1.9671 - val_accuracy: 0.5488\n",
      "Epoch 849/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8333 - val_loss: 0.6464 - val_accuracy: 0.8537\n",
      "Epoch 850/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.9136 - val_loss: 0.1757 - val_accuracy: 0.9268\n",
      "Epoch 851/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.8704 - val_loss: 0.7760 - val_accuracy: 0.8780\n",
      "Epoch 852/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1341 - accuracy: 0.9444 - val_loss: 1.1077 - val_accuracy: 0.7561\n",
      "Epoch 853/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9630 - val_loss: 0.4659 - val_accuracy: 0.9146\n",
      "Epoch 854/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9630 - val_loss: 0.5204 - val_accuracy: 0.8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9630 - val_loss: 0.6065 - val_accuracy: 0.9024\n",
      "Epoch 856/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9877 - val_loss: 5.8946 - val_accuracy: 0.2805\n",
      "Epoch 857/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.9043 - val_loss: 0.6272 - val_accuracy: 0.8902\n",
      "Epoch 858/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9815 - val_loss: 0.9319 - val_accuracy: 0.8293\n",
      "Epoch 859/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9815 - val_loss: 0.5781 - val_accuracy: 0.9024\n",
      "Epoch 860/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9846 - val_loss: 0.4609 - val_accuracy: 0.9146\n",
      "Epoch 861/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9877 - val_loss: 0.3201 - val_accuracy: 0.9512\n",
      "Epoch 862/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.9475 - val_loss: 0.6206 - val_accuracy: 0.9024\n",
      "Epoch 863/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9846 - val_loss: 0.5038 - val_accuracy: 0.9146\n",
      "Epoch 864/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 0.9846 - val_loss: 0.3520 - val_accuracy: 0.9512\n",
      "Epoch 865/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9722 - val_loss: 1.1089 - val_accuracy: 0.7927\n",
      "Epoch 866/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9568 - val_loss: 0.6089 - val_accuracy: 0.9024\n",
      "Epoch 867/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9938 - val_loss: 3.0950 - val_accuracy: 0.3902\n",
      "Epoch 868/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9537 - val_loss: 0.5382 - val_accuracy: 0.9024\n",
      "Epoch 869/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 0.9753 - val_loss: 0.6471 - val_accuracy: 0.9024\n",
      "Epoch 870/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9815 - val_loss: 3.5398 - val_accuracy: 0.4268\n",
      "Epoch 871/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9630 - val_loss: 0.8647 - val_accuracy: 0.8780\n",
      "Epoch 872/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.7549 - val_accuracy: 0.8902\n",
      "Epoch 873/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9907 - val_loss: 0.6495 - val_accuracy: 0.9024\n",
      "Epoch 874/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9969 - val_loss: 0.6113 - val_accuracy: 0.9024\n",
      "Epoch 875/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9907 - val_loss: 0.6998 - val_accuracy: 0.9024\n",
      "Epoch 876/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9938 - val_loss: 0.5096 - val_accuracy: 0.9024\n",
      "Epoch 877/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9907 - val_loss: 0.7325 - val_accuracy: 0.9024\n",
      "Epoch 878/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9938 - val_loss: 0.6529 - val_accuracy: 0.9024\n",
      "Epoch 879/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.5373 - val_accuracy: 0.9146\n",
      "Epoch 880/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.5572 - val_accuracy: 0.9024\n",
      "Epoch 881/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9907 - val_loss: 0.6388 - val_accuracy: 0.9024\n",
      "Epoch 882/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9907 - val_loss: 0.6695 - val_accuracy: 0.9024\n",
      "Epoch 883/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9938 - val_loss: 0.5717 - val_accuracy: 0.9146\n",
      "Epoch 884/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.6457 - val_accuracy: 0.9024\n",
      "Epoch 885/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9969 - val_loss: 0.6872 - val_accuracy: 0.9024\n",
      "Epoch 886/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9969 - val_loss: 0.6356 - val_accuracy: 0.9024\n",
      "Epoch 887/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9907 - val_loss: 0.5854 - val_accuracy: 0.9024\n",
      "Epoch 888/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 0.5757 - val_accuracy: 0.9024\n",
      "Epoch 889/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9907 - val_loss: 0.5904 - val_accuracy: 0.9024\n",
      "Epoch 890/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9938 - val_loss: 0.7001 - val_accuracy: 0.9024\n",
      "Epoch 891/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9938 - val_loss: 0.6591 - val_accuracy: 0.9024\n",
      "Epoch 892/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9969 - val_loss: 0.5356 - val_accuracy: 0.9146\n",
      "Epoch 893/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9846 - val_loss: 0.6115 - val_accuracy: 0.9024\n",
      "Epoch 894/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9907 - val_loss: 0.7212 - val_accuracy: 0.9024\n",
      "Epoch 895/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9969 - val_loss: 0.6149 - val_accuracy: 0.9024\n",
      "Epoch 896/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.6791 - val_accuracy: 0.9024\n",
      "Epoch 897/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9938 - val_loss: 0.4631 - val_accuracy: 0.9146\n",
      "Epoch 898/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0388 - accuracy: 0.9907 - val_loss: 0.5729 - val_accuracy: 0.9024\n",
      "Epoch 899/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9815 - val_loss: 0.6145 - val_accuracy: 0.9024\n",
      "Epoch 900/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.2380 - val_accuracy: 0.9512\n",
      "Epoch 901/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.9167 - val_loss: 1.0622 - val_accuracy: 0.8293\n",
      "Epoch 902/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.9475 - val_loss: 0.5795 - val_accuracy: 0.9024\n",
      "Epoch 903/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9753 - val_loss: 0.7207 - val_accuracy: 0.9024\n",
      "Epoch 904/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9907 - val_loss: 0.6673 - val_accuracy: 0.9024\n",
      "Epoch 905/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9907 - val_loss: 0.5261 - val_accuracy: 0.9024\n",
      "Epoch 906/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9877 - val_loss: 0.5893 - val_accuracy: 0.9024\n",
      "Epoch 907/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9938 - val_loss: 0.6015 - val_accuracy: 0.9024\n",
      "Epoch 908/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9969 - val_loss: 0.5938 - val_accuracy: 0.9024\n",
      "Epoch 909/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9938 - val_loss: 0.6444 - val_accuracy: 0.9024\n",
      "Epoch 910/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9907 - val_loss: 0.7023 - val_accuracy: 0.9024\n",
      "Epoch 911/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.5884 - val_accuracy: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9938 - val_loss: 0.6509 - val_accuracy: 0.9024\n",
      "Epoch 913/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9938 - val_loss: 0.7022 - val_accuracy: 0.9024\n",
      "Epoch 914/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 0.6273 - val_accuracy: 0.9024\n",
      "Epoch 915/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9938 - val_loss: 0.7298 - val_accuracy: 0.9024\n",
      "Epoch 916/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9907 - val_loss: 1.1617 - val_accuracy: 0.8049\n",
      "Epoch 917/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9907 - val_loss: 0.5751 - val_accuracy: 0.9024\n",
      "Epoch 918/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9907 - val_loss: 0.6475 - val_accuracy: 0.9024\n",
      "Epoch 919/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9938 - val_loss: 0.6204 - val_accuracy: 0.9024\n",
      "Epoch 920/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9938 - val_loss: 0.7044 - val_accuracy: 0.9024\n",
      "Epoch 921/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.9197 - val_accuracy: 0.8293\n",
      "Epoch 922/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9784 - val_loss: 0.4782 - val_accuracy: 0.9146\n",
      "Epoch 923/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9907 - val_loss: 0.7820 - val_accuracy: 0.9024\n",
      "Epoch 924/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9938 - val_loss: 0.5357 - val_accuracy: 0.9024\n",
      "Epoch 925/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9938 - val_loss: 0.7262 - val_accuracy: 0.9024\n",
      "Epoch 926/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9969 - val_loss: 0.6343 - val_accuracy: 0.9024\n",
      "Epoch 927/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9938 - val_loss: 0.6425 - val_accuracy: 0.9024\n",
      "Epoch 928/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9938 - val_loss: 0.7614 - val_accuracy: 0.9024\n",
      "Epoch 929/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9938 - val_loss: 0.7273 - val_accuracy: 0.9024\n",
      "Epoch 930/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9969 - val_loss: 0.6625 - val_accuracy: 0.9024\n",
      "Epoch 931/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9938 - val_loss: 0.7122 - val_accuracy: 0.9024\n",
      "Epoch 932/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9969 - val_loss: 0.7198 - val_accuracy: 0.9024\n",
      "Epoch 933/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9969 - val_loss: 0.9151 - val_accuracy: 0.8902\n",
      "Epoch 934/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.6812 - val_accuracy: 0.9024\n",
      "Epoch 935/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 0.7330 - val_accuracy: 0.9024\n",
      "Epoch 936/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9938 - val_loss: 0.5779 - val_accuracy: 0.9146\n",
      "Epoch 937/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9907 - val_loss: 0.6120 - val_accuracy: 0.9024\n",
      "Epoch 938/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9969 - val_loss: 0.6954 - val_accuracy: 0.9024\n",
      "Epoch 939/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9938 - val_loss: 0.7181 - val_accuracy: 0.9024\n",
      "Epoch 940/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9938 - val_loss: 0.6617 - val_accuracy: 0.9024\n",
      "Epoch 941/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.6317 - val_accuracy: 0.9024\n",
      "Epoch 942/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.6314 - val_accuracy: 0.9024\n",
      "Epoch 943/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9907 - val_loss: 0.7507 - val_accuracy: 0.9024\n",
      "Epoch 944/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9938 - val_loss: 0.6927 - val_accuracy: 0.9024\n",
      "Epoch 945/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.6686 - val_accuracy: 0.9024\n",
      "Epoch 946/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9907 - val_loss: 0.6556 - val_accuracy: 0.9024\n",
      "Epoch 947/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9938 - val_loss: 0.8595 - val_accuracy: 0.8659\n",
      "Epoch 948/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.7023 - val_accuracy: 0.9024\n",
      "Epoch 949/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 2.8619 - val_accuracy: 0.5610\n",
      "Epoch 950/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2246 - accuracy: 0.9383 - val_loss: 0.7873 - val_accuracy: 0.8902\n",
      "Epoch 951/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9938 - val_loss: 0.6347 - val_accuracy: 0.9024\n",
      "Epoch 952/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9969 - val_loss: 0.6917 - val_accuracy: 0.9024\n",
      "Epoch 953/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9938 - val_loss: 0.7224 - val_accuracy: 0.9024\n",
      "Epoch 954/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9969 - val_loss: 0.6798 - val_accuracy: 0.9024\n",
      "Epoch 955/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9938 - val_loss: 0.7002 - val_accuracy: 0.9024\n",
      "Epoch 956/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9938 - val_loss: 0.5844 - val_accuracy: 0.9146\n",
      "Epoch 957/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9907 - val_loss: 0.6880 - val_accuracy: 0.9024\n",
      "Epoch 958/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9969 - val_loss: 0.7046 - val_accuracy: 0.9024\n",
      "Epoch 959/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9938 - val_loss: 0.6481 - val_accuracy: 0.9024\n",
      "Epoch 960/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9938 - val_loss: 0.6529 - val_accuracy: 0.9024\n",
      "Epoch 961/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9938 - val_loss: 1.2694 - val_accuracy: 0.8049\n",
      "Epoch 962/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9938 - val_loss: 0.7025 - val_accuracy: 0.9146\n",
      "Epoch 963/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.6755 - val_accuracy: 0.9024\n",
      "Epoch 964/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9969 - val_loss: 0.7000 - val_accuracy: 0.9146\n",
      "Epoch 965/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.6594 - val_accuracy: 0.9146\n",
      "Epoch 966/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9938 - val_loss: 1.0457 - val_accuracy: 0.8049\n",
      "Epoch 967/1000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1828 - accuracy: 0.9321 - val_loss: 2.3450 - val_accuracy: 0.5488\n",
      "Epoch 968/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9722 - val_loss: 1.2715 - val_accuracy: 0.7927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9846 - val_loss: 0.5350 - val_accuracy: 0.9146\n",
      "Epoch 970/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9938 - val_loss: 0.6451 - val_accuracy: 0.9146\n",
      "Epoch 971/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9938 - val_loss: 0.6318 - val_accuracy: 0.9146\n",
      "Epoch 972/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9969 - val_loss: 0.6763 - val_accuracy: 0.9146\n",
      "Epoch 973/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9938 - val_loss: 0.6423 - val_accuracy: 0.9146\n",
      "Epoch 974/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.8192 - val_accuracy: 0.8902\n",
      "Epoch 975/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9784 - val_loss: 0.6072 - val_accuracy: 0.9024\n",
      "Epoch 976/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9938 - val_loss: 0.8640 - val_accuracy: 0.9024\n",
      "Epoch 977/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9938 - val_loss: 0.6003 - val_accuracy: 0.9024\n",
      "Epoch 978/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9938 - val_loss: 0.7192 - val_accuracy: 0.9024\n",
      "Epoch 979/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9969 - val_loss: 0.7814 - val_accuracy: 0.9024\n",
      "Epoch 980/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 1.0498 - val_accuracy: 0.8780\n",
      "Epoch 981/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9969 - val_loss: 0.7569 - val_accuracy: 0.9024\n",
      "Epoch 982/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.7284 - val_accuracy: 0.9024\n",
      "Epoch 983/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 0.7413 - val_accuracy: 0.9024\n",
      "Epoch 984/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9969 - val_loss: 1.3579 - val_accuracy: 0.8293\n",
      "Epoch 985/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9691 - val_loss: 0.5810 - val_accuracy: 0.9024\n",
      "Epoch 986/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9938 - val_loss: 0.7907 - val_accuracy: 0.9024\n",
      "Epoch 987/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9969 - val_loss: 0.7412 - val_accuracy: 0.9024\n",
      "Epoch 988/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9938 - val_loss: 0.5622 - val_accuracy: 0.9146\n",
      "Epoch 989/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.6820 - val_accuracy: 0.9024\n",
      "Epoch 990/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.6670 - val_accuracy: 0.9024\n",
      "Epoch 991/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9938 - val_loss: 0.6554 - val_accuracy: 0.9024\n",
      "Epoch 992/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9938 - val_loss: 0.7232 - val_accuracy: 0.9024\n",
      "Epoch 993/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9969 - val_loss: 0.6798 - val_accuracy: 0.9024\n",
      "Epoch 994/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9969 - val_loss: 0.6232 - val_accuracy: 0.9146\n",
      "Epoch 995/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.7088 - val_accuracy: 0.9024\n",
      "Epoch 996/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.6699 - val_accuracy: 0.9024\n",
      "Epoch 997/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.6841 - val_accuracy: 0.9024\n",
      "Epoch 998/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.6853 - val_accuracy: 0.9024\n",
      "Epoch 999/1000\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9969 - val_loss: 0.7047 - val_accuracy: 0.9024\n",
      "Epoch 1000/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.6778 - val_accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import LeakyReLU, PReLU, ELU\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(64, kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(32, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(16, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(8, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(4, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'he_uniform', activation='sigmoid'))\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss='BinaryCrossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#######################################################\n",
    "                TENSORBOARD - Starts\n",
    "#######################################################\n",
    "\"\"\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='../logs/{}'.format(int(time.time())))\n",
    "\n",
    "\n",
    "# basic_model.save \\\n",
    "#     ('C:/Users/shad_/Desktop/2. Fall 2020/CSE 6211 (Deep Learning)/Submission/Project/Covid Detection with UNet/models/basic_model')\n",
    "\n",
    "\"\"\"\n",
    "#######################################################\n",
    "                TENSORBOARD - Ends\n",
    "#######################################################\n",
    "\"\"\"\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(\n",
    "    training_features.values, \n",
    "    training_labels.values, \n",
    "    validation_split=0.20,\n",
    "    epochs = 1000,\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9778\n",
      "training loss, training acc: [0.15647993981838226, 0.9778324961662292]\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4014 - accuracy: 0.9268\n",
      "test loss, test acc: [0.40143486857414246, 0.9268292784690857]\n"
     ]
    }
   ],
   "source": [
    "results = classifier.evaluate(training_features, training_labels, batch_size=128)\n",
    "print(\"training loss, training acc:\", results)\n",
    "\n",
    "results = classifier.evaluate(testing_features, testing_labels, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4014 - accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "acc_nn = classifier.evaluate(testing_features, testing_labels, batch_size=128)[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  100.0\n",
      "Recall:  100.0\n",
      "FScore:  100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_nn = classifier.predict(testing_features)\n",
    "\n",
    "for i, num in enumerate(y_pred_nn):\n",
    "    y_pred_nn[i] = round(num[0])\n",
    "\n",
    "# print(y_pred_nn)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(testing_labels, y_pred, average='weighted')\n",
    "\n",
    "accuracy_nn = accuracy_score(testing_labels, predictions) * 100\n",
    "\n",
    "# print(\"Accuracy: \", accuracy_nn)\n",
    "print(\"Precision: \", precision*100)\n",
    "print(\"Recall: \", recall*100)\n",
    "print(\"FScore: \", fscore*100)\n",
    "# print(\"Support: \", support*100)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(testing_labels, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Printing the accuracy for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "# langs = ['C', 'C++', 'Java', 'Python', 'PHP']\n",
    "# students = [23,17,35,29,12]\n",
    "\n",
    "x = ['Logistic Regression', 'Random Forest Classifier', 'XGBoost', 'Neural Network']\n",
    "y = [acc_log_reg, acc_rf_classifier, acc_XGB_classifier, accuracy_nn]\n",
    "# y = [acc_log_reg, 10, acc_XGB_classifier, acc_nn]\n",
    "\n",
    "ax.bar(x, y)\n",
    "\n",
    "# ax = result.plot(kind='bar', figsize=(15,4), width=0.8, color=colors_list, edgecolor=None)\n",
    "\n",
    "#################################################################\n",
    "\n",
    "for p in ax.patches:\n",
    "#     print(p)\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate(f'{height}', (x + width/2, y + height*1.02), ha='center')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
